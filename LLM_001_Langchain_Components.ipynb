{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChainì˜ ê°œë…ê³¼ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì´í•´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChainì´ë€ \n",
    "\n",
    "- **LangChain**ì€ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "- **Chain**ì€ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ ì œê³µ\n",
    "\n",
    "- **Agent**ëŠ” ììœ¨ì  ì˜ì‚¬ê²°ì •ì´ ê°€ëŠ¥í•œ ì‹¤í–‰ ë‹¨ìœ„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain ì»´í¬ë„ŒíŠ¸ \n",
    "\n",
    "- **ì–¸ì–´ ì²˜ë¦¬ ê¸°ëŠ¥**ì€ LLM/ChatModelì´ ì¤‘ì‹¬ì´ ë˜ë©°, Promptì™€ Memoryë¡œ ëŒ€í™”ë¥¼ ê´€ë¦¬\n",
    "\n",
    "- **ë¬¸ì„œ ì²˜ë¦¬ì™€ ê²€ìƒ‰**ì€ Document Loader, Text Splitter, Embedding, Vectorstoreê°€ ë‹´ë‹¹\n",
    "\n",
    "- **ëª¨ë“ˆì„±**ì´ í•µì‹¬ íŠ¹ì§•ìœ¼ë¡œ, ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì¡°í•©í•´ RAGì™€ ê°™ì€ ë³µì¡í•œ ì‹œìŠ¤í…œì„ êµ¬í˜„ ê°€ëŠ¥ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# uv add ipykernel python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env íŒŒì¼ ì„¤ì •\n",
    "# OPENAI_API_KEY=your_openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyCZaxMg76R4-PjsMEbNz1yLjdqY50ESQJk'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ëª¨ë¸ (Models)\n",
    "- LLM, ChatModel ë“±ìœ¼ë¡œ êµ¬ë¶„\n",
    "- OpenAI, Anthropic, Google ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›\n",
    "- í…ìŠ¤íŠ¸ ìƒì„±, ëŒ€í™”, ìš”ì•½ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'type': 'text', 'text': \"ê¸ˆê°•ì‚°ë„ ì‹í›„ê²½ì´ë¼ëŠ”ë°, ì–¼ë¥¸ ë§›ìˆëŠ” ê±¸ ë“œì…”ì•¼ê² ì–´ìš”! ë©”ë‰´ ê³ ë¥´ëŠ” ê²Œ ì„¸ìƒì—ì„œ ì œì¼ ì–´ë ¤ìš´ ì¼ì´ì£ . ê²°ì •ì— ë„ì›€ì„ ë“œë¦¬ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ìƒí™©ë³„ë¡œ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.\\n\\nì§€ê¸ˆ ì–´ë–¤ ê²Œ ê°€ì¥ ë‹¹ê¸°ì‹œë‚˜ìš”?\\n\\n**1. ë“ ë“ í•˜ê³  ë”°ëœ»í•œ í•œì‹ì´ ë‹¹ê¸´ë‹¤ë©´?**\\n*   **ê¹€ì¹˜ì°Œê°œë‚˜ ëœì¥ì°Œê°œ:** ë”°ëˆí•œ êµ­ë¬¼ì— ë°¥ í•œ ê·¸ë¦‡ ëšë”±!\\n*   **ì œìœ¡ë³¶ìŒ:** ë§¤ì½¤ë‹¬ì½¤í•œ ê³ ê¸° ë°˜ì°¬ì€ ì‹¤íŒ¨ê°€ ì—†ì£ .\\n*   **ë¹„ë¹”ë°¥:** ëƒ‰ì¥ê³  ë‚¨ì€ ì±„ì†Œ ë„£ê³  ìŠ¥ìŠ¥ ë¹„ë²¼ ë“œì„¸ìš”.\\n\\n**2. ê°„ë‹¨í•˜ê³  ë¹ ë¥´ê²Œ ë¨¹ê³  ì‹¶ë‹¤ë©´?**\\n*   **ë¼ë©´ ë˜ëŠ” ì§œíŒŒê²Œí‹°:** ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•œ í–‰ë³µì´ì£ .\\n*   **ìƒŒë“œìœ„ì¹˜ë‚˜ í† ìŠ¤íŠ¸:** ê¹”ë”í•˜ê²Œ í•œ ë¼ í•´ê²°í•˜ê¸° ì¢‹ì•„ìš”.\\n*   **í¸ì˜ì  ë„ì‹œë½/ì‚¼ê°ê¹€ë°¥:** ì„ íƒì§€ê°€ ë‹¤ì–‘í•´ì„œ ê³¨ë¼ ë¨¹ëŠ” ì¬ë¯¸ê°€ ìˆì–´ìš”.\\n\\n**3. ìŠ¤íŠ¸ë ˆìŠ¤ í’€ë¦¬ëŠ” ë§¤ì½¤í•˜ê±°ë‚˜ ìê·¹ì ì¸ ë§›?**\\n*   **ë–¡ë³¶ì´:** íŠ€ê¹€ì´ë‘ ìˆœëŒ€ê¹Œì§€ ê³ë“¤ì´ë©´ ì™„ë²½!\\n*   **ë§ˆë¼íƒ•:** ì¢‹ì•„í•˜ëŠ” ì¬ë£Œ ë“¬ë¿ ë„£ì–´ì„œ ì–¼í°í•˜ê²Œ ì–´ë– ì„¸ìš”?\\n*   **ë¶ˆë‹­ë³¶ìŒë©´:** í™”ëˆí•˜ê²Œ ë§¤ìš´ë§›ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ë‚ ë ¤ë²„ë¦¬ê¸°!\\n\\n**4. ê¸°ë¦„ì§€ê³  ë°°ë¶€ë¥¸ 'ì¹˜íŒ… ë°ì´' ëŠë‚Œ?**\\n*   **ì¹˜í‚¨:** ì˜¤ëŠ˜ í•˜ë£¨ ê³ ìƒí•œ ë‚˜ì—ê²Œ ì£¼ëŠ” ì„ ë¬¼!\\n*   **ì‚¼ê²¹ì‚´:** ì§€ê¸€ì§€ê¸€ êµ¬ìš´ ê³ ê¸°ì— ìŒˆ ì‹¸ ë¨¹ê¸°.\\n*   **í–„ë²„ê±°:** ì½œë¼ì™€ ê°ìíŠ€ê¹€ì˜ ì™„ë²½í•œ ì¡°í™”.\\n\\n**5. ê°€ë³ê³  ê±´ê°•í•˜ê²Œ ë¨¹ê³  ì‹¶ë‹¤ë©´?**\\n*   **í¬ì¼€ë‚˜ ìƒëŸ¬ë“œ:** ì‹ ì„ í•œ ì±„ì†Œì™€ ì—°ì–´/ë‹­ê°€ìŠ´ì‚´ì˜ ì¡°í•©.\\n*   **ìƒ¤ë¸Œìƒ¤ë¸Œ:** ì±„ì†Œë¥¼ ë§ì´ ë¨¹ì„ ìˆ˜ ìˆì–´ ì†ì´ í¸í•´ìš”.\\n\\n**ê²°ì •í•˜ê¸° í˜ë“¤ë‹¤ë©´ ì œê°€ ê³¨ë¼ë“œë¦´ê¹Œìš”?**\\nì§€ê¸ˆ **'ë§¤ì½¤, ë‹´ë°±, ëŠë¼, ë‹¬ì½¤'** ì¤‘ì— í•˜ë‚˜ë§Œ ê³¨ë¼ë³´ì„¸ìš”! í˜¹ì€ ëƒ‰ì¥ê³ ì— ìˆëŠ” ì¬ë£Œë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ìš”ë¦¬ë¥¼ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”. ğŸ˜‰\", 'extras': {'signature': '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'}}], additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-3-flash-preview', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b492f-8cd0-7d62-891e-2074cd7fb48c-0', usage_metadata={'input_tokens': 4, 'output_tokens': 1084, 'total_tokens': 1088, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 563}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    temperature=0,  # Gemini 3.0+ defaults to 1.0\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "response1 = model.invoke(\"ë°°ê³ íŒŒ\")\n",
    "\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0, max_completion_tokens=512)\n",
    "\n",
    "# ëª¨ë¸ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ê¸°\n",
    "response = model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f0bc439dc3', 'id': 'chatcmpl-Cpn4xllc4fgxXarCfNNXiAAbYEPwA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b492f-b16a-75d2-8279-c24c7ae1735f-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´(AIMessage): ë©”ì‹œì§€(content)ì™€ ë©”íƒ€ë°ì´í„°(response_metadata ë“±)ë¥¼ í¬í•¨\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´ì˜ ë©”ì‹œì§€ ë‚´ìš© ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë©”íƒ€ë°ì´í„°:  {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f0bc439dc3', 'id': 'chatcmpl-Cpn4xllc4fgxXarCfNNXiAAbYEPwA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´ì˜ ë©”íƒ€ë°ì´í„° ì¶œë ¥\n",
    "print(\"ë©”íƒ€ë°ì´í„°: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ë©”ì‹œì§€ (Messages)\n",
    "- Chat Modelì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í†µí•©ëœ ë©”ì‹œì§€ í˜•ì‹ì„ ì œê³µ\n",
    "- ê° ëª¨ë¸ ì œê³µìì˜ íŠ¹ì • ë©”ì‹œì§€ í˜•ì‹ì„ ì‹ ê²½ ì“°ì§€ ì•Šê³ ë„ ë‹¤ì–‘í•œ ì±„íŒ… ëª¨ë¸ì„ í™œìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- ì‚¬ìš©ì ì—­í• ì— í•´ë‹¹ (user, human ë“±)\n",
    "- ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  \"Glory\"ëŠ” í•œêµ­ì–´ë¡œ \"ì˜ê´‘\" ë˜ëŠ” \"ì˜ì˜ˆ\"ë¼ê³  ë²ˆì—­ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„±\n",
    "human_message = HumanMessage(content=\"Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ë²ˆì—­ ìš”ì²­ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke([human_message])  # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬\n",
    "\n",
    "# ë‹µë³€ ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content) #contentì†ì„±ìœ¼ë¡œ ë‚´ë³´ëƒ„."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"ëŠ” í•œêµ­ì–´ë¡œ \"ì˜ê´‘\" ë˜ëŠ” \"ì˜ì˜ˆ\"ë¼ê³  ë²ˆì—­ë©ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 17, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f0bc439dc3', 'id': 'chatcmpl-Cpn4ysVjK3mWCc68WkADj1DcVBDGQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b492f-b7d0-7712-aab1-441633ad642e-0', usage_metadata={'input_tokens': 17, 'output_tokens': 22, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¬¸ìì—´ì„ ì…ë ¥í•˜ë©´, ìë™ìœ¼ë¡œ HumanMessageë¡œ ë³€í™˜í•˜ì—¬ ìš”ì²­\n",
    "model.invoke(\"Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI ëª¨ë¸ì˜ ì‘ë‹µì„ í‘œí˜„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Glory\"ëŠ” í•œêµ­ì–´ë¡œ \"ì˜ê´‘\" ë˜ëŠ” \"ì˜ì˜ˆ\"ë¼ê³  ë²ˆì—­ë©ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 17, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f0bc439dc3', 'id': 'chatcmpl-Cpn4x4LihUiWhAUSd7nseT6S21fXt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b492f-b3de-7002-847b-d12608d2fd4b-0', usage_metadata={'input_tokens': 17, 'output_tokens': 22, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI ëª¨ë¸ì˜ ì‘ë‹µ ê°ì²´ë¥¼ ì¶œë ¥ \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‘ë‹µ ê°ì²´ì˜ ìë£Œí˜• í™•ì¸\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Glory\"ëŠ” í•œêµ­ì–´ë¡œ \"ì˜ê´‘\" ë˜ëŠ” \"ì˜ì˜ˆ\"ë¼ê³  ë²ˆì—­ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ë¶€ë¶„ì„ ì¶œë ¥\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 17,\n",
       " 'output_tokens': 22,\n",
       " 'total_tokens': 39,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- ì‹œìŠ¤í…œ ì—­í• ì— í•´ë‹¹ (system, developer ë“±)\n",
    "- AI ëª¨ë¸ì˜ ë™ì‘ê³¼ ì œì•½ì‚¬í•­ì„ ì •ì˜í•˜ëŠ”ë° ì‚¬ìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage \n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±\n",
    "system_msg = SystemMessage(content=\"ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë©”ì‹œì§€ ê°ì²´ í™•ì¸\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€:  ì˜ê´‘\n"
     ]
    }
   ],
   "source": [
    "# ë²ˆì—­ ìš”ì²­ (HumanMessage)ê³¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€(SystemMessage)ë¥¼ í•¨ê»˜ ì‚¬ìš©\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "messages = [system_msg, human_message]\n",
    "\n",
    "# ëª¨ë¸ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# ë‹µë³€ ì¶œë ¥\n",
    "print(\"ë‹µë³€: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Template)\n",
    "- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´ ì¼ê´€ëœ ì…ë ¥ í˜•ì‹ì„ ì œê³µ\n",
    "    1. ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì–¸ì–´ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬\n",
    "    2. ì–¸ì–´ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  ì§€ì‹œë¬¸ì„ ë§Œë“œëŠ” í‹€\n",
    "- ë³€ìˆ˜ë¥¼ í¬í•¨í•œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ê°€ëŠ¥\n",
    "    1. ëª¨ë“  í…œí”Œë¦¿ì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ì„ ë°›ì•„ì„œ ì²˜ë¦¬\n",
    "    2. ì¶œë ¥ì€ PromptValue í˜•íƒœë¡œ ë°˜í™˜ë˜ë©°, ì´ëŠ” ë¬¸ìì—´ì´ë‚˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (String PromptTemplate)`\n",
    "- ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœ\n",
    "- ë‹¨ì¼ ë¬¸ìì—´ì„ í˜•ì‹í™”í•˜ëŠ”ë° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='ê³ ì–‘ì´ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„± \n",
    "# \"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\"ë¼ëŠ” í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬\n",
    "# topicì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±\n",
    "template = PromptTemplate.from_template(\"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "# \"ê³ ì–‘ì´\"ë¼ëŠ” ì£¼ì œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# invoke ë©”ì„œë“œë¥¼ í†µí•´ í…œí”Œë¦¿ì— ê°’ì„ ì „ë‹¬\n",
    "prompt = template.invoke({\"topic\": \"ê³ ì–‘ì´\"})\n",
    "\n",
    "# í…œí”Œë¦¿ ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ChatPromptTemplate)`\n",
    "- ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ëŠ” ëŒ€í™”í˜• í…œí”Œë¦¿ì„ ë§Œë“¤ ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}), HumanMessage(content='ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ì±„íŒ… í…œí”Œë¦¿ ìƒì„±\n",
    "# ì—¬ê¸°ì„œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ì—¬ ì •ì˜\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "    (\"user\", \"{subject}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "])\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = template.invoke({\"subject\": \"ì¸ê³µì§€ëŠ¥\"}) #invokeëŠ”ë°ì´í„°ì¸í’‹í•´ì„œëŒë ¤ë°›ì„ë•Œì“°ëŠ”ê¸°ë³¸ì‹¤í–‰ë§¤ì„œë“œ\n",
    "\n",
    "# ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë” (MessagesPlaceholder)`\n",
    "- ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ì„ í…œí”Œë¦¿ì˜ íŠ¹ì • ìœ„ì¹˜ì— ì‚½ì…í•  ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ìŠ¤í‹°ë¸Œì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í…œí”Œë¦¿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "    MessagesPlaceholder(\"chat_history\")   # ì±„íŒ… ê¸°ë¡ì„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì‚¬ìš© (ì˜ˆ: ì´ì „ ëŒ€í™” ë‚´ìš©) -> ì´ ìœ„ì¹˜ì— ë©”ì‹œì§€ ëª©ë¡ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ\n",
    "]) #ë©”ì„¸ì§€ë“¤ì˜ ëª©ë¡ì„ íŠ¹ì •í•œëª©ë¡ì— ë„£ê³ ì‹¶ì„ë•Œ, ì±„íŒ…ê¸°ë¡ì„ íŠ¹ì •ìœ„ì¹˜ì—ë„£ê³ ì‹¶ì„ë•Œ ì‚¬ìš©í•œë‹¤. ë©”ì„¸ì§€ê°€ ë¦¬ìŠ¤íŠ¸í˜•íƒœë¡œ ë“¤ì–´ì˜¨ë‹¤.\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = template.invoke({\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ìŠ¤í‹°ë¸Œì…ë‹ˆë‹¤.\"),\n",
    "        AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "        HumanMessage(content=\"ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ë‚˜ìš”?\")\n",
    "        ]\n",
    "})\n",
    "\n",
    "# ì¶œë ¥\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ì¶œë ¥ íŒŒì„œ (Output Parser)\n",
    "1. **ì—­í• ê³¼ ê¸°ëŠ¥**\n",
    "    - ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "    - ì±„íŒ… ëª¨ë¸ê³¼ LLMì˜ ì¶œë ¥ì„ ì •ê·œí™”\n",
    "    - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ ìœ„í•œ ë°ì´í„° í˜•ì‹ ë³€í™˜\n",
    "\n",
    "2. **ì‚¬ìš© ì‹œ ê³ ë ¤ì‚¬í•­**\n",
    "    - OpenAI function callingê³¼ ê°™ì€ ê¸°ëŠ¥ì´ ìˆëŠ” ê²½ìš°, í•´ë‹¹ ê¸°ëŠ¥ì„ ìš°ì„  ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ê²½ì œ, ë¬¸í™”, ì •ì¹˜ì˜ ì¤‘ì‹¬ì§€ë¡œì„œ ë‹¤ì–‘í•œ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. í˜„ëŒ€ì™€ ì „í†µì´ ê³µì¡´í•˜ëŠ” ë„ì‹œ: ì„œìš¸ì€ ê³ ê¶ê³¼ ì‚¬ì› ë“± ì „í†µì ì¸ ìœ ì ì§€ì™€ í•¨ê»˜ ì²¨ë‹¨ ë¹Œë”©ê³¼ í˜„ëŒ€ì ì¸ ì¸í”„ë¼ê°€ ì–´ìš°ëŸ¬ì ¸ ìˆì–´ ê³¼ê±°ì™€ í˜„ì¬ê°€ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. ë›°ì–´ë‚œ êµí†µë§: ì§€í•˜ì² , ë²„ìŠ¤, ê³ ì†ë„ë¡œ ë“± ë‹¤ì–‘í•œ êµí†µìˆ˜ë‹¨ì´ ì˜ ë°œë‹¬ë˜ì–´ ìˆì–´ ë„ì‹œ ë‚´ ì´ë™ì´ í¸ë¦¬í•©ë‹ˆë‹¤. ì¸ì²œêµ­ì œê³µí•­ì´ ì¸ì ‘í•´ ìˆì–´ êµ­ì œ êµí†µì˜ í—ˆë¸Œ ì—­í• ë„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. ê²½ì œ ì¤‘ì‹¬ì§€: ì‚¼ì„±, LG, í˜„ëŒ€ ë“± êµ­ë‚´ ëŒ€í‘œ ê¸°ì—…ë“¤ì˜ ë³¸ì‚¬ê°€ ìœ„ì¹˜í•´ ìˆìœ¼ë©°, ê¸ˆìœµ, ë¬´ì—­, ì‚°ì—…ì˜ í•µì‹¬ì§€ë¡œì„œ ëŒ€í•œë¯¼êµ­ ê²½ì œë¥¼ ì´ë„ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. ë¬¸í™”ì™€ ì˜ˆìˆ ì˜ ì¤‘ì‹¬: êµ­ë¦½ê·¹ì¥, ì˜ˆìˆ ì˜ì „ë‹¹, ì„œìš¸ì‹œë¦½ë¯¸ìˆ ê´€ ë“± ë‹¤ì–‘í•œ ë¬¸í™”ì‹œì„¤ì´ ìˆìœ¼ë©°, ì „í†µê³¼ í˜„ëŒ€ ì˜ˆìˆ ì´ ìœµí•©ëœ ë‹¤ì–‘í•œ ë¬¸í™” í–‰ì‚¬ê°€ ì—´ë¦½ë‹ˆë‹¤.\n",
      "\n",
      "5. êµìœ¡ê³¼ ì—°êµ¬ì˜ ì¤‘ì‹¬: ì„œìš¸ëŒ€í•™êµ, ì—°ì„¸ëŒ€í•™êµ, ì´í™”ì—¬ìëŒ€í•™êµ ë“± êµ­ë‚´ ìµœê³ ì˜ ëŒ€í•™ë“¤ì´ ìœ„ì¹˜í•´ í•™ë¬¸ê³¼ ì—°êµ¬ì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤.\n",
      "\n",
      "6. ìì—°ê³¼ íœ´ì‹ ê³µê°„: ë‚¨ì‚°, í•œê°•, ì„œìš¸ìˆ² ë“± ìì—°ê³¼ ì ‘í•  ìˆ˜ ìˆëŠ” ê³µê°„ì´ ë§ì•„ ì‹œë¯¼ë“¤ì´ ì—¬ê°€ë¥¼ ì¦ê¸°ê¸°ì— ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ ì„œìš¸ì€ ì „í†µê³¼ í˜„ëŒ€, ìì—°ê³¼ ë„ì‹œê°€ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§„ ë‹¤ì±„ë¡œìš´ ë„ì‹œì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê¸°ë³¸ì ì¸ ë¬¸ìì—´ íŒŒì„œ ì‚¬ìš©\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate.from_template(\"ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | model | parser #lcelë¬¸ë²•ì´ë¼ê³  ë¶€ë¥¸ë‹¤. ëª¨ë¸ì´ì¶œë ¥í•œê±¸ ai messageë¡œ ì¶œë ¥ë˜ë‹ˆê¹Œ, \n",
    "#ëŒ€í‘œì ì¸ê²Œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” íŒŒì„œê°€ stroutputparser ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì²´ì¸ì²˜ëŸ¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°ì‹œí‚¨ë‹¤. í”„ë¡¬í”„íŠ¸>ëª¨ë¸>íŒŒì„œ ì´ìˆœì„œë¡œê°„ë‹¤.\n",
    "#ì„¸ê°€ì§€ ì»´í¬ë„ŒíŠ¸ê°€ í•˜ë‚˜ì˜ ì²´ì¸ìœ¼ë¡œ ì—°ê²°. \n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"city\": \"ì„œìš¸\"}) #ì‹œí‹°ë³€ìˆ˜ì— ì„œìš¸ë°ì´í„°ê°€ í”„ë¡¬í”„íŠ¸ì—ê²Œ ê°€ê³  í”„ë¡¬í”„íŠ¸ì™„ì„±ë˜ë©´ ëª¨ë¸ë¡œê°€ê³  íœ´ë©´ë©”ì„¸ì§€ì „ë‹¬\n",
    "#aië©”ì„¸ì§€ê°€ íŒŒì„œë¡œê°€ê³  ìµœì¢…ì¶œë ¥ì€ aië©”ì„¸ì§€ê°€ ì•„ë‹ˆë¼ ë¬¸ìì—´ë¡œ ë‚¨ê²Œ ëœë‹¤. êµ¬ì¡°ë¥¼ ì´í•´í• ë•ŒëŠ” ë­ìŠ¤ë¯¸ìŠ¤ë¥¼ ê¼­ í™œìš©í•´ë¼.\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) êµ¬ì¡°í™”ëœ ì¶œë ¥ (with_structured_output ë©”ì†Œë“œ)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field #jsonëª¨ë¸ë¡œë½‘ì•„ë‚´ëŠ”ê±°ê³  íŒŒì´ë´í‹±ì„ë§Œì´ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "# Pydantic í´ë˜ìŠ¤ë¡œ ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜ #ì‹œí‹°ì¸í¬ì •ë³¼ë¥´ ì¶œë ¥í• ê±°ë‹¤. ë„ì‹œ ì •ë³´ë¥¼ ë„¤ì„ì´ë‘ ì„¤ëª…ìœ¼ë¡œ í´ë˜ìŠ¤ë¡œ ë½‘ê² ë‹¤ê³  ì •ì˜í•œê±°.\n",
    "class CityInfo(BaseModel):\n",
    "    name: str = Field(description=\"ë„ì‹œ ì´ë¦„\")\n",
    "    description: str = Field(description=\"ë„ì‹œì˜ íŠ¹ì§•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(\"ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° êµ¬ì¡°í™”ëœ ì¶œë ¥ ë°”ì¸ë”©\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "structured_model = model.with_structured_output(CityInfo) #ìœ„ë“œìŠ¤íŠ¸ëŸ­í‹°ë“œ apiê°€ìˆëŠ”ë° ê·¸ê±¸ ì ìš©í•˜ë©´, ì¶œë ¥ì´ ì•ì—\n",
    "#cityinfo í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ì´ ë˜ê²Œ ëœë‹¤.\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ ì²´ì¸ ì—°ê²°\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"city\": \"ì„œìš¸\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CityInfo'>\n",
      "--------------------\n",
      "name='ì„œìš¸' description='ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ë¡œ, ê²½ì œ, ë¬¸í™”, ì •ì¹˜ì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤. í˜„ëŒ€ì ì¸ ë„ì‹œì™€ ì „í†µì ì¸ ë¬¸í™”ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê²½ë³µê¶, ëª…ë™, ê°•ë‚¨ ë“± ë‹¤ì–‘í•œ ëª…ì†Œì™€ í™œê¸°ì°¬ ë„ì‹œ ìƒí™œì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'\n",
      "--------------------\n",
      "ë„ì‹œ ì´ë¦„: ì„œìš¸\n",
      "íŠ¹ì§•: ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ë¡œ, ê²½ì œ, ë¬¸í™”, ì •ì¹˜ì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤. í˜„ëŒ€ì ì¸ ë„ì‹œì™€ ì „í†µì ì¸ ë¬¸í™”ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê²½ë³µê¶, ëª…ë™, ê°•ë‚¨ ë“± ë‹¤ì–‘í•œ ëª…ì†Œì™€ í™œê¸°ì°¬ ë„ì‹œ ìƒí™œì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥ (CityInfo ê°ì²´)\n",
    "print(type(result))\n",
    "print(\"-\" * 20)\n",
    "print(result)\n",
    "print(\"-\" * 20)\n",
    "print(f\"ë„ì‹œ ì´ë¦„: {result.name}\")\n",
    "print(f\"íŠ¹ì§•: {result.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ì‹¤ìŠµ] \n",
    "\n",
    "- êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì‚¬ìš©í•˜ì—¬, ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì–¸ë¡ ì‚¬, ê¸°ì‚¬ ì œëª©, ê¸°ì‚¬ ë‚´ìš©, ì‘ì„±ì, ì‘ì„±ì¼ì„ ì¶”ì¶œí•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "news_article = \"\"\"\n",
    "\"ë³µì¡í•œ ë‚©ì„¸ ë“± AIê°€ ë•ëŠ”ë‹¤\"â€¦ì •ë¶€, ì´ˆê±°ëŒ€ AI ê³µê³µì„œë¹„ìŠ¤ ê°œë°œ\n",
    "ì…ë ¥2025.06.20. ì˜¤í›„ 12:00  ìˆ˜ì •2025.06.20. ì˜¤í›„ 1:39 \n",
    "\n",
    "[ì„œìš¸=ë‰´ì‹œìŠ¤]ìœ¤í˜„ì„± ê¸°ì = ì •ë¶€ê°€ ê³µê³µë¶„ì•¼ì— ë„ì…í•  ì´ˆê±°ëŒ€ ì¸ê³µì§€ëŠ¥(AI) ê¸°ë°˜ êµ­ë¯¼ í¸ì˜ ì„œë¹„ìŠ¤ ë³¸ê²© ê°œë°œì— ë‚˜ì„ ë‹¤. ì„¸ê¸ˆ ë‚©ë¶€ ì‹œ ìƒì„±í˜• AI ì±—ë´‡ì„ í†µí•´ ì–´ë ¤ìš´ ì„¸ë¬´ ìš©ì–´ ë“±ì— ëŒ€í•œ ì„¤ëª…Â·ìƒë‹´ì„ ë“£ê±°ë‚˜, ëŒ€ëŸ‰ì˜ ë¯¼ì›ì—…ë¬´ë„ ìƒì„±í˜• AI ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ë‹µë³€Â·ì‘ëŒ€í•˜ëŠ” ë“±ì˜ í˜•íƒœë‹¤.\n",
    "\n",
    "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì™€ ë””ì§€í„¸í”Œë«í¼ì •ë¶€ìœ„ì›íšŒëŠ” 2025ë…„ë„ 'ì´ˆê±°ëŒ€ AI ì„œë¹„ìŠ¤ ê°œë°œ ì§€ì›' ì‚¬ì—…ì„ ë³¸ê²© ì¶”ì§„í•˜ê¸° ìœ„í•´ ìˆ˜í–‰ê¸°ì—… ê³µëª¨ë¥¼ ì‹¤ì‹œí•œë‹¤ê³  20ì¼ ë°í˜”ë‹¤. ì´ ì‚¬ì—…ì€ ê³µê³µë¶„ì•¼ì— ì´ˆê±°ëŒ€ AIë¥¼ ë„ì…Â·í™•ì‚°í•˜ê³  ì´ë¥¼ í†µí•´ í–‰ì • íš¨ìœ¨í™”, ëŒ€êµ­ë¯¼ ì„œë¹„ìŠ¤ í˜ì‹ , ì‚¬íšŒí˜„ì•ˆ í•´ê²°ì´ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ê°œë°œì„ ëª©í‘œë¡œ ì¶”ì§„ëœë‹¤.\n",
    "\n",
    "ì˜¬í•´ëŠ” ë‹¤ì–‘í•œ ê³µê³µë¶„ì•¼ì—ì„œ ì´ˆê±°ëŒ€ AI ê¸°ìˆ ì„ í†µí•´ êµ­ë¯¼ì´ ì²´ê°í•  ìˆ˜ ìˆê³  ì‹¤ì§ˆì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ê³¼ì œë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë°œêµ´í–ˆë‹¤. ì¤‘ì•™ë¶€ì²˜Â·ì§€ìì²´Â·ê³µê³µê¸°ê´€ì„ ëŒ€ìƒìœ¼ë¡œ 1~2ì›”ì— ê³¼ì œ ê³µëª¨ë¥¼ ì¶”ì§„í–ˆìœ¼ë©° ì´ 5ê°œ ê³¼ì œê°€ ì„ ì •ëë‹¤.\n",
    "\n",
    "êµ­ë¯¼ê¶Œìµìœ„ì›íšŒì˜ 'ìƒì„±í˜• AI ê¸°ë°˜ êµ­ë¯¼ì†Œí†µÂ·ë¯¼ì›ë¶„ì„ ì²´ê³„ êµ¬ì¶•'ì€ êµ­ë¯¼ì†Œí†µì‹œìŠ¤í…œì— ìƒì„±í˜• AI ê¸°ë°˜ ë¯¼ì›ë¶„ì„ ì²´ê³„ë¥¼ ë„ì…í•´ ë¯¼ì›ì²˜ë¦¬ í–‰ì • íš¨ìœ¨í™”ì™€ ë‹µë³€í’ˆì§ˆì„ í–¥ìƒì‹œí‚¨ë‹¤. ì´ë¥¼ í†µí•´ ëŒ€ëŸ‰ì˜ ë¯¼ì›ì—…ë¬´ë¥¼ ì‹ ì†Â·íš¨ìœ¨ì ìœ¼ë¡œ ëŒ€ì‘í•´ ë¯¼ì›ì—…ë¬´ì˜ íš¨ìœ¨ì„±ì„ ì¦ëŒ€í•˜ê³  êµ­ë¯¼ì˜ ì‹ ë¢°ë„ í–¥ìƒì—ë„ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.\n",
    "\n",
    "êµ­ì„¸ì²­ì˜ 'ìƒì„±í˜• AI ê¸°ë°˜ êµ­ì„¸ ìƒë‹´ ì§€ì› ì„œë¹„ìŠ¤'ëŠ” ë‚©ì„¸ìê°€ í™ˆíƒìŠ¤ ì´ìš© ì‹œ ì „ìì‹ ê³  ê´€ë ¨í•œ ë¬¸ì˜ì‚¬í•­ì„ ì¦‰ì‹œ í•´ì†Œí•  ìˆ˜ ìˆëŠ” ì‹¤ì‹œê°„ ìƒë‹´ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•œë‹¤. í™ˆíƒìŠ¤ì— ìƒë‹´ì „ìš© AIì±—ë´‡ì„ ë„ì…í•´ ì „í™” ìƒë‹´ ì‹œ ë°œìƒí•˜ëŠ” ì¥ì‹œê°„ ëŒ€ê¸° ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì–´ë ¤ìš´ ì„¸ë¬´ ìš©ì–´ ë“±ìœ¼ë¡œ ì¸í•œ ë¶ˆí¸ì‚¬í•­ì„ ê°œì„ í•  ì˜ˆì •ì´ë‹¤.\n",
    "\n",
    "ì‚°ì—…í†µìƒìì›ë¶€ì˜ 'í•´ì™¸ì¸ì¦ ê³µê³µíŠ¹í™” AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤'ëŠ” ëª¨ë°”ì¼ í”Œë«í¼, ì†Œì…œë„¤íŠ¸ì›Œí¬ì„œë¹„ìŠ¤ ë“± ì‚¬ìš©ì ì¹œí™”ì ì¸ ëª¨ë°”ì¼ ê¸°ë°˜ í•´ì™¸ì¸ì¦ íŠ¹í™” AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•œë‹¤. ì¤‘ì†Œê¸°ì—…ì´ ê²ªëŠ” ìˆ˜ì¶œ ê´€ë ¨ ì• ë¡œì‚¬í•­ì¸ í•´ì™¸ ì¸ì¦ê³¼ ê´€ë ¨ëœ ì •ë³´ì™€ ì§ˆì˜ ì‘ë‹µì„ AIê¸°ë°˜ìœ¼ë¡œ ì œê³µí•˜ì—¬ ì†ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.\n",
    "\n",
    "êµ­ë¯¼ê±´ê°•ë³´í—˜ê³µë‹¨ì˜ 'ì—ì´ì „í‹± AIê¸°ë°˜ ì „êµ­ë¯¼ ë§ì¶¤í˜• ë¯¼ì› ìƒë‹´ ì„œë¹„ìŠ¤'ëŠ” êµ­ë¯¼ ìƒí™œê³¼ í¸ìµì— ì§ê²°ë˜ëŠ” ê±´ê°•ë³´í—˜ ë¯¼ì› ìƒë‹´ì—…ë¬´ì— AIë¥¼ ë„ì…í•´ 24ì‹œê°„ ê°œì¸ ë§ì¶¤í˜• ë¯¼ì› ìƒë‹´ ì„œë¹„ìŠ¤ë¥¼ êµ¬í˜„í•œë‹¤. ê¸°ì¡´ì˜ ì „í™” ìƒë‹´ ë°©ì‹ì˜ ëŒ€ê¸° ì‹œê°„ ë¬¸ì œ ë“±ì„ í•´ì†Œí•˜ê³ , ê³ ê°ì„¼í„° ì§‘ì¤‘ ìƒë‹´ì„ ë¶„ì‚°ì‹œì¼œ ì—…ë¬´ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ”ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì „ë§ì´ë‹¤.\n",
    "\n",
    "í•œêµ­ì§€ì—­ì •ë³´ê°œë°œì›ì˜ 'ì§€ë°©ì¬ì • ì§€ëŠ¥í™” ì„œë¹„ìŠ¤'ëŠ” eí˜¸ì¡°+, ì§€ë°©ì¬ì •365 ë“± ì§€ë°©ì¬ì •ì„œë¹„ìŠ¤ì— ìƒì„±í˜• AIë¥¼ ì ‘ëª©ì‹œì¼œ ëŒ€êµ­ë¯¼, ê³µë¬´ì› ë“± ê°ìì˜ ìš”êµ¬ì— ë¶€í•©í•˜ëŠ” ìœµë³µí•© ì¬ì •ì •ë³´ì„œë¹„ìŠ¤ í™˜ê²½ì„ ì œê³µí•˜ê³ ì í•œë‹¤. ì´ ì„œë¹„ìŠ¤ê°€ ë„ì…ë˜ë©´ ì§€ë°©ì •ë¶€ì˜ ì‚¬íšŒí˜„ì•ˆ í•´ê²°ì„ ìœ„í•œ ì •ì±… ìˆ˜ë¦½ì˜ ì ì‹œì„± í–¥ìƒ ë° ì „ë¬¸ì„± í™•ë³´, ì§€ìì²´ ì •ë³´ ì ‘ê·¼ì„± ê°•í™”ë¡œ ëŒ€êµ­ë¯¼ì˜ ì‚¬íšŒ ì°¸ì—¬ ê¸°íšŒë¥¼ í™•ëŒ€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.\n",
    "\n",
    "ì´ë²ˆ ì‚¬ì—…ì€ 19ì¼ êµ­ë¯¼ê¶Œìµìœ„ì›íšŒì™€ êµ­ì„¸ì²­ ê³¼ì œì˜ ë¯¼ê°„ ì „ë¬¸ê¸°ì—… ì¡°ë‹¬ ê³µê³ ë¥¼ ì‹œì‘ìœ¼ë¡œ, 5ê°œ ê³¼ì œë³„ ì„œë¹„ìŠ¤ ê°œë°œì§€ì› ì‚¬ì—…ì´ ìˆœì°¨ì ìœ¼ë¡œ ì…ì°°ê³µê³ ë  ì˜ˆì •ì´ë‹¤.\n",
    "\n",
    "ê¹€ê²½ë§Œ ê³¼ê¸°ì •í†µë¶€ ì¸ê³µì§€ëŠ¥ê¸°ë°˜ì •ì±…ê´€ì€ \"ì„ ì •ëœ ê³¼ì œì— ëŒ€í•´ ë¯¼Â·ê´€ í˜‘ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ í–‰ì • í˜„ì¥ì˜ ë³€í™”ì™€ êµ­ë¯¼ì´ ì²´ê°í•  ìˆ˜ ìˆëŠ” ì„±ê³¼ê°€ ì°½ì¶œÂ·í™•ì‚°ë  ìˆ˜ ìˆë„ë¡ ì ê·¹ ì§€ì›í•  ê³„íš\"ì´ë¼ë©° \"ê°œë°œëœ ì„œë¹„ìŠ¤ëŠ” ê³µê³µë¶„ì•¼ì—ì„œ í–‰ì •ì—…ë¬´ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ëŒ€êµ­ë¯¼ ì„œë¹„ìŠ¤ í’ˆì§ˆì„ ë†’ì´ëŠ” ë° ì‹¤ì§ˆì ìœ¼ë¡œ ê¸°ì—¬í•  ìˆ˜ ìˆë„ë¡ ë¯¼ê°„ì—ì„œë„ ë§ì€ ê´€ì‹¬ì„ ê°€ì ¸ì£¼ì‹¤ ê²ƒì„ ë¶€íƒë“œë¦°ë‹¤\"ê³  ë§í–ˆë‹¤.\n",
    "\n",
    "ì´ìŠ¹í˜„ ë””í”Œì •ìœ„ ì¸ê³µì§€ëŠ¥Â·í”Œë«í¼í˜ì‹ êµ­ì¥ì€ \"ì´ë²ˆ ì‚¬ì—…ì€ ë…¸ë™, ë³µì§€, ë¯¼ì› ë“± ë‹¤ì–‘í•œ ê³µê³µ ë¶„ì•¼ì— AIë¥¼ ë„ì…Â·í™œìš©í•˜ëŠ”ë° ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆë‹¤\"ë©° \"ì˜¬í•´ë„ AIë¥¼ í™œìš©í•´ ì‚¬íšŒë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ëŒ€êµ­ë¯¼ ì„œë¹„ìŠ¤ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ê°€ ê°œë°œë˜ê¸¸ ê¸°ëŒ€í•œë‹¤\"ê³  ì „í–ˆë‹¤ï¼\n",
    "\n",
    "ìœ¤í˜„ì„± ê¸°ì(hsyhs@newsis.com)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”. \n",
    "\n",
    "news_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„± \n",
    "# \"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\"ë¼ëŠ” í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬\n",
    "# topicì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±\n",
    "template = PromptTemplate.from_template(\"{news_article}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "# \"ê³ ì–‘ì´\"ë¼ëŠ” ì£¼ì œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# invoke ë©”ì„œë“œë¥¼ í†µí•´ í…œí”Œë¦¿ì— ê°’ì„ ì „ë‹¬\n",
    "prompt = template.invoke({\"topic\": \"ê³ ì–‘ì´\"})\n",
    "\n",
    "# í…œí”Œë¦¿ ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê¸°ë³¸ì ì¸ ë¬¸ìì—´ íŒŒì„œ ì‚¬ìš©\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate.from_template(\"news_articleì„ \")\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | model | parser #lcelë¬¸ë²•ì´ë¼ê³  ë¶€ë¥¸ë‹¤. ëª¨ë¸ì´ì¶œë ¥í•œê±¸ ai messageë¡œ ì¶œë ¥ë˜ë‹ˆê¹Œ, \n",
    "#ëŒ€í‘œì ì¸ê²Œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” íŒŒì„œê°€ stroutputparser ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì²´ì¸ì²˜ëŸ¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°ì‹œí‚¨ë‹¤. í”„ë¡¬í”„íŠ¸>ëª¨ë¸>íŒŒì„œ ì´ìˆœì„œë¡œê°„ë‹¤.\n",
    "#ì„¸ê°€ì§€ ì»´í¬ë„ŒíŠ¸ê°€ í•˜ë‚˜ì˜ ì²´ì¸ìœ¼ë¡œ ì—°ê²°. \n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"city\": \"ì„œìš¸\"}) #ì‹œí‹°ë³€ìˆ˜ì— ì„œìš¸ë°ì´í„°ê°€ í”„ë¡¬í”„íŠ¸ì—ê²Œ ê°€ê³  í”„ë¡¬í”„íŠ¸ì™„ì„±ë˜ë©´ ëª¨ë¸ë¡œê°€ê³  íœ´ë©´ë©”ì„¸ì§€ì „ë‹¬\n",
    "#aië©”ì„¸ì§€ê°€ íŒŒì„œë¡œê°€ê³  ìµœì¢…ì¶œë ¥ì€ aië©”ì„¸ì§€ê°€ ì•„ë‹ˆë¼ ë¬¸ìì—´ë¡œ ë‚¨ê²Œ ëœë‹¤. êµ¬ì¡°ë¥¼ ì´í•´í• ë•ŒëŠ” ë­ìŠ¤ë¯¸ìŠ¤ë¥¼ ê¼­ í™œìš©í•´ë¼.\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œëª©:  ë³µì¡í•œ ë‚©ì„¸ ë“± AIê°€ ë•ëŠ”ë‹¤â€¦ì •ë¶€, ì´ˆê±°ëŒ€ AI ê³µê³µì„œë¹„ìŠ¤ ê°œë°œ\n",
      "ë³¸ë¬¸:  ì •ë¶€ëŠ” ê³µê³µë¶„ì•¼ì— ì´ˆê±°ëŒ€ ì¸ê³µì§€ëŠ¥(AI) ê¸°ë°˜ êµ­ë¯¼ í¸ì˜ ì„œë¹„ìŠ¤ ê°œë°œì„ ì¶”ì§„í•œë‹¤. ì„¸ê¸ˆ ë‚©ë¶€, ë¯¼ì›ì—…ë¬´, í•´ì™¸ì¸ì¦, ê±´ê°•ë³´í—˜ ë¯¼ì› ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ AIë¥¼ í™œìš©í•œ ì„œë¹„ìŠ¤ê°€ ë„ì…ë  ì˜ˆì •ì´ë©°, ì´ë¥¼ í†µí•´ í–‰ì • íš¨ìœ¨í™”ì™€ êµ­ë¯¼ ì„œë¹„ìŠ¤ í˜ì‹ ì´ ê¸°ëŒ€ëœë‹¤. ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì™€ ë””ì§€í„¸í”Œë«í¼ì •ë¶€ìœ„ì›íšŒëŠ” 2025ë…„ 'ì´ˆê±°ëŒ€ AI ì„œë¹„ìŠ¤ ê°œë°œ ì§€ì›' ì‚¬ì—…ì„ ê³µëª¨í•˜ë©°, 5ê°œ ê³¼ì œë¥¼ ì„ ì •í•˜ì—¬ ë¯¼ê°„ê¸°ì—…ê³¼ í˜‘ë ¥í•´ ê°œë°œì„ ì§„í–‰í•œë‹¤.\n",
      "ì‘ì„±ì:  ìœ¤í˜„ì„± ê¸°ì\n",
      "ì‘ì„±ì¼:  2025-06-20\n",
      "ì œê³µ ê¸°ê´€:  ë‰´ì‹œìŠ¤\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class NewsSummary(BaseModel):\n",
    "    title: str = Field(description=\"ë‰´ìŠ¤ ì œëª©\")\n",
    "    content: str = Field(description=\"ë‰´ìŠ¤ ë³¸ë¬¸\")\n",
    "    author: str = Field(description=\"ì‘ì„±ì\")\n",
    "    published_date: str = Field(description=\"ì‘ì„±ì¼\")\n",
    "    agency: str = Field(description=\"ë‰´ìŠ¤ ì œê³µ ê¸°ê´€\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\\n\\n{news_article}\\n\\n\"\n",
    "              \"ì œëª©, ë³¸ë¬¸, ì‘ì„±ì, ì‘ì„±ì¼, ì œê³µ ê¸°ê´€ì„ í¬í•¨í•œ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "])\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸ ìƒì„±\n",
    "structured_model = model.with_structured_output(NewsSummary)\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"news_article\": news_article})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì œëª©: \", result.title)\n",
    "print(\"ë³¸ë¬¸: \", result.content)\n",
    "print(\"ì‘ì„±ì: \", result.author)\n",
    "print(\"ì‘ì„±ì¼: \", result.published_date)\n",
    "print(\"ì œê³µ ê¸°ê´€: \", result.agency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
    "\n",
    "```python\n",
    "# ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class NewsSummary(BaseModel):\n",
    "    title: str = Field(description=\"ë‰´ìŠ¤ ì œëª©\")\n",
    "    content: str = Field(description=\"ë‰´ìŠ¤ ë³¸ë¬¸\")\n",
    "    author: str = Field(description=\"ì‘ì„±ì\")\n",
    "    published_date: str = Field(description=\"ì‘ì„±ì¼\")\n",
    "    agency: str = Field(description=\"ë‰´ìŠ¤ ì œê³µ ê¸°ê´€\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\\n\\n{news_article}\\n\\n\"\n",
    "              \"ì œëª©, ë³¸ë¬¸, ì‘ì„±ì, ì‘ì„±ì¼, ì œê³µ ê¸°ê´€ì„ í¬í•¨í•œ ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "])\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ ëª¨ë¸ ìƒì„±\n",
    "structured_model = model.with_structured_output(NewsSummary)\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | structured_model\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"news_article\": news_article})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì œëª©: \", result.title)\n",
    "print(\"ë³¸ë¬¸: \", result.content)\n",
    "print(\"ì‘ì„±ì: \", result.author)\n",
    "print(\"ì‘ì„±ì¼: \", result.published_date)\n",
    "print(\"ì œê³µ ê¸°ê´€: \", result.agency)\n",
    "```\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "004-llm-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
