{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2217fa83",
      "metadata": {},
      "source": [
        "# **LangSmith ëª¨ë‹ˆí„°ë§**: LLM Observability\n",
        "\n",
        "- LangSmithëŠ” **LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê´€ì°°ì„±(Observability)** ì˜µì…˜ì„ ì œê³µí•˜ëŠ” ë„êµ¬ì„.\n",
        "\n",
        "- ê°œë°œìê°€ LLM ì²´ì¸ê³¼ ì—ì´ì „íŠ¸ë¥¼ **íš¨ê³¼ì ìœ¼ë¡œ ë””ë²„ê¹…**í•˜ê³  ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•¨.\n",
        "\n",
        "- ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ì²´ì¸ ì‹¤í–‰ **ë¡œê¹… ë° ì¶”ì **ì´ í¬í•¨ë¨.\n",
        "\n",
        "- **í”„ë¡¬í”„íŠ¸ ë””ë²„ê¹…**ê³¼ ì„±ëŠ¥ ì¸¡ì • ë° ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•¨."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd9328",
      "metadata": {
        "id": "8bfd9328"
      },
      "source": [
        "### LangSmith í™˜ê²½ ì„¤ì •\n",
        "\n",
        "- langsmith ê°€ì… í•„ìš” (https://www.langchain.com/langsmith)\n",
        "- ìœ ë£Œ (ê°œì¸ ê°œë°œì ëŒ€ìƒ ë¶€ë¶„ ë¬´ë£Œ)\n",
        "\n",
        "- .env íŒŒì¼ì— í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
        "    ```\n",
        "    LANGSMITH_TRACING=your_langsmith_api_key\n",
        "    LANGSMITH_TRACING=true\n",
        "    LANGSMITH_PROJECT=your_project_name \n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "15ac3ddb",
      "metadata": {
        "id": "15ac3ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Langsmith tracing ì—¬ë¶€ë¥¼ í™•ì¸ \n",
        "import os\n",
        "print(os.getenv('LANGSMITH_TRACING'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129b8eee",
      "metadata": {
        "id": "129b8eee"
      },
      "source": [
        "---\n",
        "\n",
        "# LCEL(LangChain Expression Language) \n",
        "\n",
        "- **LCEL**ì€ `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ì„ ì–¸ì  ì²´ì´ë‹ì„ ì§€ì›í•©ë‹ˆë‹¤\n",
        "\n",
        "- **ì¬ì‚¬ìš©ì„±**ì´ ë†’ì•„ ì •ì˜ëœ ì²´ì¸ì„ ë‹¤ë¥¸ ì²´ì¸ì˜ ì»´í¬ë„ŒíŠ¸ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "\n",
        "- **ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹**(.invoke(), .batch(), .stream(), .astream())ìœ¼ë¡œ ë™ê¸°/ë¹„ë™ê¸° ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
        "\n",
        "- **ë°°ì¹˜ ì²˜ë¦¬**ì‹œ ìë™ ìµœì í™”ë¥¼ í†µí•´ íš¨ìœ¨ì ì¸ ì‘ì—… ìˆ˜í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68074eb8",
      "metadata": {
        "id": "68074eb8"
      },
      "source": [
        "#### 1) **Prompt + LLM**\n",
        "\n",
        "* ê¸°ë³¸ êµ¬ì¡°: `Prompt | LLM` í˜•íƒœë¡œ, íŒŒì´í”„(|) ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸ì™€ LLMì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.\n",
        "\n",
        "* ë°ì´í„° íë¦„: ì‚¬ìš©ì ì…ë ¥ì´ Prompt í…œí”Œë¦¿ì„ í†µí•´ ì²˜ë¦¬ëœ í›„, LLMì— ì „ë‹¬ë˜ì–´ ìµœì¢… ì‘ë‹µì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
        "\n",
        "* ì‹¤í–‰ ìˆœì„œ: íŒŒì´í”„ë¼ì¸ì€ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ê° ì»´í¬ë„ŒíŠ¸ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ì»´í¬ë„ŒíŠ¸ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3722db67",
      "metadata": {
        "id": "3722db67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-nano\", \n",
        "    temperature=0.3, \n",
        "    top_p=0.95,\n",
        "    )\n",
        "\n",
        "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥\n",
        "response = llm.invoke(\"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0113cf90",
      "metadata": {
        "id": "0113cf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í…œí”Œë¦¿ ë³€ìˆ˜:\n",
            "- í•„ìˆ˜ ë³€ìˆ˜: ['question', 'topic']\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# í…œí”Œë¦¿ ë¬¸ìì—´ ì •ì˜\n",
        "template = \"\"\"\n",
        "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "ì§ˆë¬¸: {question}\n",
        "ë‹µë³€: \"\"\"\n",
        "\n",
        "# PromptTemplate ê°ì²´ ìƒì„±\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "print(\"í…œí”Œë¦¿ ë³€ìˆ˜:\")\n",
        "print(f\"- í•„ìˆ˜ ë³€ìˆ˜: {prompt.input_variables}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c801f727",
      "metadata": {
        "id": "c801f727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# chainì„ êµ¬ì„±\n",
        "chain = prompt | llm\n",
        "\n",
        "# chain ì‹¤í–‰\n",
        "response = chain.invoke( \n",
        "    {\n",
        "        \"topic\": \"í™”í•™(Chemistry)\", \n",
        "        \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983d4157",
      "metadata": {
        "id": "983d4157"
      },
      "source": [
        "#### **2) Prompt + LLM + Output Parser**\n",
        "\n",
        "* ë°ì´í„° íŒŒì´í”„ë¼ì¸: `Prompt | LLM | OutputParser` í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ LLMì˜ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "* Parser ì¢…ë¥˜: JSON, XML ë“± ë‹¤ì–‘í•œ í˜•ì‹ì˜ íŒŒì„œë¥¼ ì§€ì›í•˜ì—¬ LLM ì¶œë ¥ì„ ì›í•˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* ìœ íš¨ì„± ê²€ì¦: Parserê°€ ì¶œë ¥ í˜•ì‹ì„ ê²€ì¦í•˜ì—¬ ì˜ëª»ëœ í˜•ì‹ì˜ ì‘ë‹µì„ í•„í„°ë§í•˜ê³  ì•ˆì •ì ì¸ ë°ì´í„° ì²˜ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6b7607",
      "metadata": {
        "id": "7e6b7607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "### ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ \n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ì¶œë ¥ íŒŒì„œë¥¼ ìƒì„±\n",
        "output_parser = StrOutputParser() #ë¬¸ìì—´ íŒŒì„œë‹ˆê¹Œ aiì—ì„œ ë‚˜ì˜¨ ë‚´ìš©ì„ llmìœ¼ë¡œ í•œë‹¤.\n",
        "\n",
        "# ì¶œë ¥ íŒŒì„œë¥¼ chainì— ì¶”ê°€\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chainì„ ì‹¤í–‰\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"topic\": \"í™”í•™(Chemistry)\", \n",
        "        \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4456bde9",
      "metadata": {
        "id": "4456bde9"
      },
      "source": [
        "---\n",
        "# **Runnable**\n",
        "\n",
        "* ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤: ëª¨ë“  LangChain ì»´í¬ë„ŒíŠ¸ëŠ” Runnable ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
        "\n",
        "* ì‹¤í–‰ ë©”ì„œë“œ: `.invoke()`, `.batch()`, `.stream()`, `.astream()` ë“± ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "* í˜¸í™˜ì„±: ëª¨ë“  Runnable ì»´í¬ë„ŒíŠ¸ëŠ” íŒŒì´í”„(|) ì—°ì‚°ìë¥¼ í†µí•´ ì—°ê²° ê°€ëŠ¥í•˜ë©°, ì¬ì‚¬ìš©ì´ ìš©ì´í•©ë‹ˆë‹¤.\n",
        "\n",
        "* Runnableì˜ ì£¼ìš” ìœ í˜•:\n",
        "\n",
        "    * `RunnableSequence`: ì—¬ëŸ¬ Runnableì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰\n",
        "    * `RunnablePassthrough`: ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬    \n",
        "    * `RunnableParallel`: ì—¬ëŸ¬ Runnableì„ ë³‘ë ¬ë¡œ ì‹¤í–‰\n",
        "    * `RunnableLambda`: íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ Runnableë¡œ ë˜í•‘í•˜ì—¬ ì²´ì¸ì—ì„œ ì‚¬ìš©, ë°”ë¡œ ëŸ¬ë„ˆë¸”ê°’ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d0cfd",
      "metadata": {},
      "source": [
        "#### 1) **RunnableSequence**\n",
        "\n",
        "- **RunnableSequence**ëŠ” ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì—°ê²°í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì²´ì¸ì…ë‹ˆë‹¤\n",
        "\n",
        "- `|` ì—°ì‚°ìë¡œ ì—°ê²°ëœ ê° ë‹¨ê³„ì˜ **ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥**ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤\n",
        "\n",
        "- **ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹**(ë™ê¸°/ë¹„ë™ê¸°, ë°°ì¹˜/ìŠ¤íŠ¸ë¦¬ë°)ì„ ì§€ì›í•©ë‹ˆë‹¤\n",
        "\n",
        "- LLM ì²´ì¸, ë°ì´í„° íŒŒì´í”„ë¼ì¸, ìë™í™”ëœ ì‘ì—… ë“± **ë‹¤ë‹¨ê³„ ì²˜ë¦¬**ì— í™œìš©ë©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7c9cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
        "prompt = PromptTemplate.from_template(\"'{text}'ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ë¬¸ì¥ë§Œì„ ì¶œë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4.1-nano\", \n",
        "    temperature=0.3, \n",
        "    top_p=0.95\n",
        ")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# RunnableSequence ìƒì„± - í•¨ìˆ˜ ì‚¬ìš© \n",
        "translation_chain = RunnableSequence(\n",
        "    first=prompt,\n",
        "    middle=[model],   # ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ëŠ” ì ì— ì£¼ì˜, ë¯¸ë“¤ë§Œ ì—¬ëŸ¬ê°œì „í•´ì£¼ë ¤ê³  ë¦¬ìŠ¤íŠ¸\n",
        "    last=output_parser\n",
        ")\n",
        "\n",
        "# RunnableSequence ìƒì„± - ì—°ì‚°ì ì‚¬ìš© íŒŒ\n",
        "# translation_chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ae5ff8cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "# ë™ê¸° ì‹¤í–‰\n",
        "result = translation_chain.invoke({\"text\": \"ì•ˆë…•í•˜ì„¸ìš”\"})\n",
        "print(result)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8695d8e",
      "metadata": {},
      "source": [
        "#### 2) **RunnableLambda**\n",
        "\n",
        "- **RunnableLambda**ëŠ” ì¼ë°˜ í•¨ìˆ˜ë¥¼ Runnable ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” ë˜í¼ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤\n",
        "\n",
        "- ì²´ì¸ì— **ì»¤ìŠ¤í…€ ë¡œì§**ì„ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆì–´ ë°ì´í„° ì „ì²˜ë¦¬, í›„ì²˜ë¦¬ì— ìœ ìš©í•©ë‹ˆë‹¤\n",
        "\n",
        "- `|` ì—°ì‚°ìë¡œ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ë“¤ê³¼ ì—°ê²°í•´ **ë³µì¡í•œ ì²˜ë¦¬ íë¦„**ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "065dff4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "import re #ëŸ¬ë„ˆë¸”ëŒë‹¤ê°€ ë§ì‰ì‚¬ìš©ëœë‹¤. íŒŒì´ì¬í•¨ìˆ˜ë¥¼ ëŸ¬ë„ˆë¸”ëŒë‹¤ì˜ ê°ì²´ì— ë­ì²´ì¸ì»´í¬ë„ŒíŠ¸ë¡œë°”ê¿”ë²„ë¦°ë‹¤.\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ #ì •ìˆ˜íŒ¨í„´ë§Œì°¾ì•„ì„œ ì¶”ì¶œí•´ì£¼ëŠ”.\n",
        "def extract_number(query):\n",
        "    return int(re.search(r'\\d+', query).group())\n",
        "\n",
        "# RunnablePassthroughë¡œ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ê³ , RunnableLambdaë¡œ ìˆ«ì ì¶”ì¶œ í•¨ìˆ˜ ì‹¤í–‰\n",
        "runnable = RunnableLambda(extract_number)\n",
        "\n",
        "# ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ 6ì„ ì¶”ì¶œ\n",
        "result = runnable.invoke('íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.')\n",
        "print(result)  # ì¶œë ¥: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ea16f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì²˜ë¦¬ëœ ì‘ë‹µ: ARTIFICIAL INTELLIGENCE IS THE DEVELOPMENT OF COMPUTER SYSTEMS THAT CAN PERFORM TASKS TYPICALLY REQUIRING HUMAN INTELLIGENCE, SUCH AS LEARNING, REASONING, AND PROBLEM-SOLVING.\n",
            "ì‘ë‹µ ê¸¸ì´: 175\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì…ë ¥ê°’ ì „ì²˜ë¦¬, í›„ì²˜ë¦¬ ,í‰ê°€í•œë‹¤ê±°ë‚˜\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\" ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ì–‘ìª½ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤. \"\"\"\n",
        "    return text.strip().lower()\n",
        "\n",
        "# í›„ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
        "def postprocess_response(response: AIMessage) -> dict:\n",
        "    \"\"\" ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜í•˜ê³  ê¸¸ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. \"\"\"\n",
        "    response_text = response.content\n",
        "    return {\n",
        "        \"processed_response\": response_text.upper(),\n",
        "        \"length\": len(response_text)\n",
        "    }\n",
        "#í•„ìš”ë¡œí•˜ëŠ” ê°’ë“¤ì„ êµ¬ì¡°í™”í•´ì„œ ì¶œë ¥í•˜ëŠ” ê²ƒë“¤ì´ ì¤‘ìš”í•˜ë‹¤. ê°€ê³µì„í•´ì„œ ì¶œë ¥êµ¬ì¡°ë¡œë°”ê¾¸ëŠ”ê²ƒë„ ì¤‘ìš”í•˜ë‹¤.\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
        "prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì˜ì–´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”: {topic}\")\n",
        "\n",
        "# ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
        "chain = (\n",
        "    RunnableLambda(preprocess_text) |  # ì…ë ¥ ì „ì²˜ë¦¬ ì „ì²´ë¥¼ ëŸ¬ë„ˆë¸”ëŒë‹¤ë¡œ ì”Œìš´ê±° ëŸ¬ë„ˆë¸” ì‹€í€€ìŠ¤ì´ë‹¤. 4ê°œë¡œì§œì—¬ì§„.\n",
        "    prompt |                           # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
        "    llm |                              # LLM ì¶”ë¡ \n",
        "    RunnableLambda(postprocess_response)  # ì¶œë ¥ í›„ì²˜ë¦¬ \n",
        ")\n",
        "\n",
        "# ì²´ì¸ ì‹¤í–‰\n",
        "result = chain.invoke(\"  Artificial Intelligence  \")\n",
        "print(f\"ì²˜ë¦¬ëœ ì‘ë‹µ: {result['processed_response']}\")\n",
        "print(f\"ì‘ë‹µ ê¸¸ì´: {result['length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb7e8bf",
      "metadata": {},
      "source": [
        "#### 3) **RunnableParallel**\n",
        "\n",
        "- **RunnableParallel**ì€ ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ êµ¬ì„±í•´ **ë™ì‹œ ì‹¤í–‰**í•©ë‹ˆë‹¤\n",
        "\n",
        "- ë™ì¼í•œ ì…ë ¥ì´ ëª¨ë“  ë³‘ë ¬ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬ë˜ë©°, ê²°ê³¼ëŠ” **í‚¤-ê°’ ìŒ**ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤\n",
        "\n",
        "- **ë°ì´í„° ë³€í™˜**ê³¼ **íŒŒì´í”„ë¼ì¸ êµ¬ì„±**ì— íŠ¹í™”ë˜ì–´ ìˆìœ¼ë©°, ì¶œë ¥ í˜•ì‹ì„ ë‹¤ìŒ ë‹¨ê³„ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625baaa0",
      "metadata": {},
      "source": [
        "`(1) ì§ˆë¬¸ ë¶„ì„ ì²´ì¸`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3132cd5d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë¶„ë¥˜: í™”í•™(Chemistry)\n",
            "ì´ìœ : íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ì›ì ë²ˆí˜¸(í”„ë¡œí†¤ ìˆ˜)ê°€ 6ìœ¼ë¡œ, ì´ëŠ” ì›ì†Œì˜ íŠ¹ì„±ì„ ê²°ì •í•˜ëŠ” í•µì‹¬ ì •ë³´ì´ë©° í™”í•™ì  ì„±ì§ˆê³¼ ê´€ë ¨ì´ ê¹Šê¸° ë•Œë¬¸ì— í™”í•™ ë¶„ì•¼ì— ì†í•œë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "# Pydantic ëª¨ë¸ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ì •ì˜ ëŸ¬ë„ˆë¸”íŒ¨ëŸ¬ë ì€ ë”•ì…”ë„ˆë¦¬ì´ë‹¤.\n",
        "class SubjectClassification(BaseModel):\n",
        "    \"\"\"ì§ˆë¬¸ì˜ ì£¼ì œ ë¶„ë¥˜ ê²°ê³¼\"\"\" #ì…‹ì¤‘ì—í•˜ë‚˜ ë‚˜ì˜¤ê²Œí•œë‹¤ ì¹´í…Œê³ ë¦¬ì†ì„±ì— ì¶œë ¥ì„í•´ì¤€ë‹¤.\n",
        "    category: Literal[\"í™”í•™(Chemistry)\", \"ë¬¼ë¦¬(Physics)\", \"ìƒë¬¼(Biology)\"] = Field(\n",
        "        description=\"ì§ˆë¬¸ì´ ì†í•˜ëŠ” ê³¼í•™ ë¶„ì•¼ ì¹´í…Œê³ ë¦¬\"\n",
        "    )\n",
        "    reasoning: str = Field(\n",
        "        description=\"ë¶„ë¥˜ ì´ìœ ì— ëŒ€í•œ ì§§ì€ ì„¤ëª…\" #ëª¨ë¸í•œí…Œ ìƒê°í•˜ë„ë¡í•˜ë©´ ì¶œë ¥í’ˆì§ˆì´ ì¢‹ì•„ì§„ë‹¤. chain of sortì™€ ë¹„ìŠ·\n",
        "    )\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ #ì§ˆë¬¸ì„ ì„¸ê°œì˜ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•œë‹¤. ìœ ì €ë©”ì„¸ì§€ë¡œ ì§ˆë¬¸ ë°›ê³ , ëª¨ë¸ì€ ì…‹ì¤‘ì˜í•˜ë‚˜ì˜ í˜•íƒœë¡œ ëŒ€ë‹µí•œë‹¤.\n",
        "classification_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"\"\"ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ ê³¼í•™ ë¶„ì•¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.\n",
        "        ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•´ë‹¹í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¡œ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì•¼ í•œë‹¤.\n",
        "        \n",
        "        ë¶„ë¥˜ ê¸°ì¤€:\n",
        "        - í™”í•™(Chemistry): ì›ì†Œ, í™”í•©ë¬¼, ë°˜ì‘, ë¶„ì êµ¬ì¡° ë“±\n",
        "        - ë¬¼ë¦¬(Physics): í˜, ìš´ë™, ì—ë„ˆì§€, íŒŒë™, ì „ê¸° ë“±  \n",
        "        - ìƒë¬¼(Biology): ìƒëª…ì²´, ì„¸í¬, ìœ ì „, ìƒíƒœê³„ ë“±\"\"\"\n",
        "    ),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì‚¬ìš©í•œ ì²´ì¸ êµ¬ì„±\n",
        "structured_llm = llm.with_structured_output(SubjectClassification) #ì´ê±¸ë¡œ êµ¬ì¡°í™”ëœ ì•„ì›ƒí’‹ë‚˜ì˜¤ê²Œí•œë‹¤.\n",
        "classification_chain = classification_prompt | structured_llm\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "result = classification_chain.invoke({\"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"}) #êµ¬ì¡°í™”ëœì¶œë ¥ìœ¼ë¡œ ë‚˜ì˜¤ê²Œí•œë‹¤.\n",
        "\n",
        "# ê²°ê³¼ëŠ” Pydantic ê°ì²´ë¡œ ë°˜í™˜ë¨\n",
        "print(f\"ë¶„ë¥˜: {result.category}\")\n",
        "print(f\"ì´ìœ : {result.reasoning}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa45a8",
      "metadata": {},
      "source": [
        "`(2) ì–¸ì–´ ê°ì§€ ì²´ì¸`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d7ef5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ì…ë ¥: What is the atomic number of carbon?\n",
            "ì–¸ì–´: ì˜ì–´(English)\n",
            "ì„¤ëª…: ì œê³µëœ í…ìŠ¤íŠ¸ëŠ” ì˜ì–´ ë‹¨ì–´ì™€ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, ì˜ì–´ íŠ¹ìœ ì˜ ì•ŒíŒŒë²³ê³¼ ë¬¸ë²• íŒ¨í„´ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "--------------------------------\n",
            "\n",
            "ì…ë ¥: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
            "ì–¸ì–´: í•œêµ­ì–´(Korean)\n",
            "ì„¤ëª…: ì œê³µëœ í…ìŠ¤íŠ¸ëŠ” í•œê¸€ ë¬¸ìë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, 'íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?'ë¼ëŠ” ë¬¸ì¥ì€ í•œêµ­ì–´ ë¬¸ë²•ê³¼ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì–´ í•œêµ­ì–´ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n",
            "--------------------------------\n",
            "\n",
            "ì…ë ¥: Â¿CuÃ¡l es el nÃºmero atÃ³mico del carbono?\n",
            "ì–¸ì–´: ìŠ¤í˜ì¸ì–´(Spanish)\n",
            "ì„¤ëª…: ë¬¸ì¥ì—ì„œ ì‚¬ìš©ëœ ë‹¨ì–´ì™€ ë¬¸ë²• êµ¬ì¡°ê°€ ìŠ¤í˜ì¸ì–´ì˜ íŠ¹ì§•ì„ ë³´ì´ë©°, 'Â¿'ì™€ '?'ë¡œ ê°ì‹¸ì§„ ì˜ë¬¸ë¬¸ í˜•ì‹ì„ ê°–ì¶”ê³  ìˆì–´ ìŠ¤í˜ì¸ì–´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
            "--------------------------------\n",
            "\n",
            "ì…ë ¥: ç¢³çš„åŸå­åºæ•°æ˜¯å¤šå°‘ï¼Ÿ\n",
            "ì–¸ì–´: ì¤‘êµ­ì–´(Chinese)\n",
            "ì„¤ëª…: ì œê³µëœ í…ìŠ¤íŠ¸ëŠ” ì¤‘êµ­ì–´ ë¬¸ì ì²´ê³„ë¥¼ ì‚¬ìš©í•˜ë©°, 'åŸå­åºæ•°'ë¼ëŠ” í‘œí˜„ì€ í™”í•™ ì›ì†Œì˜ ì›ìë²ˆí˜¸ë¥¼ ì˜ë¯¸í•˜ëŠ” ì¤‘êµ­ì–´ í‘œí˜„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ í…ìŠ¤íŠ¸ëŠ” ì¤‘êµ­ì–´ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.\n",
            "--------------------------------\n",
            "\n",
            "ì…ë ¥: ç‚­ç´ ã®åŸå­ç•ªå·ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
            "ì–¸ì–´: ì¤‘êµ­ì–´(Chinese)\n",
            "ì„¤ëª…: í…ìŠ¤íŠ¸ì— ì‚¬ìš©ëœ ë¬¸ì ì²´ê³„ëŠ” í•œì(æ¼¢å­—)ë¡œ, ì´ëŠ” ì¤‘êµ­ì–´, ì¼ë³¸ì–´, ë˜ëŠ” í•œêµ­ì–´ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì¥ì˜ êµ¬ì¡°ì™€ ì˜ë¯¸ë¥¼ ê³ ë ¤í•  ë•Œ, 'ç‚­ç´ ã®åŸå­ç•ªå·ã¯ä½•ã§ã™ã‹ï¼Ÿ'ëŠ” ì¼ë³¸ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³´ì´ë©°, ì¼ë³¸ì–´ëŠ” ì¼ë³¸ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ëœë‹¤. ë”°ë¼ì„œ ì´ í…ìŠ¤íŠ¸ëŠ” ì¼ë³¸ì–´ë¡œ íŒë‹¨ëœë‹¤.\n",
            "--------------------------------\n",
            "\n",
            "ì…ë ¥: Qual Ã© o nÃºmero atÃ´mico do carbono?\n",
            "ì–¸ì–´: ìŠ¤í˜ì¸ì–´(Spanish)\n",
            "ì„¤ëª…: ì œì‹œëœ í…ìŠ¤íŠ¸ëŠ” í¬ë¥´íˆ¬ê°ˆì–´ë¡œ ë³´ì´ì§€ë§Œ, í¬ë¥´íˆ¬ê°ˆì–´ì™€ ë§¤ìš° ìœ ì‚¬í•œ ìŠ¤í˜ì¸ì–´ì˜ ë¬¸ë²•ê³¼ ì–´íœ˜ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, 'Qual Ã© o'ëŠ” í¬ë¥´íˆ¬ê°ˆì–´ì™€ ìŠ¤í˜ì¸ì–´ ëª¨ë‘ì—ì„œ 'ë¬´ì—‡ì´ëƒ' ë˜ëŠ” 'ì–´ë–¤'ì„ ì˜ë¯¸í•˜ëŠ” í‘œí˜„ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ 'nÃºmero atÃ´mico do carbono'ëŠ” 'íƒ„ì†Œì˜ ì›ìë²ˆí˜¸'ë¥¼ ì˜ë¯¸í•˜ëŠ” ê³¼í•™ì  í‘œí˜„ìœ¼ë¡œ, í¬ë¥´íˆ¬ê°ˆì–´ì™€ ìŠ¤í˜ì¸ì–´ ëª¨ë‘ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ì™€ ì–´íœ˜ëŠ” í¬ë¥´íˆ¬ê°ˆì–´ì— ê°€ê¹ì§€ë§Œ, ìš”ì²­ì— ë”°ë¼ ìŠ¤í˜ì¸ì–´ë¡œ íŒë‹¨í•˜ì˜€ìœ¼ë©°, í¬ë¥´íˆ¬ê°ˆì–´ì™€ ë§¤ìš° ìœ ì‚¬í•œ ì–¸ì–´ì„ì„ ê³ ë ¤í•˜ì˜€ìŒ.\n",
            "--------------------------------\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, Optional\n",
        "\n",
        "# Pydantic ëª¨ë¸ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ì •ì˜\n",
        "class LanguageDetection(BaseModel):\n",
        "    \"\"\"í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ ê°ì§€ ê²°ê³¼\"\"\" #ì¶œë ¥ê²°ê³¼ë¥¼ ìš°ë¦¬ê°€ ì„¤ì •í•œ ì¹´í…Œê³ ë¦¬ë¡œ ì„¤ì •ê°€ëŠ¥í•˜ë‹¤.\n",
        "\n",
        "    detected_language: Literal[\"ì˜ì–´(English)\", \"í•œêµ­ì–´(Korean)\", \"ìŠ¤í˜ì¸ì–´(Spanish)\", \"ì¤‘êµ­ì–´(Chinese)\", \"ì¼ë³¸ì–´(Japanese)\", \"ê¸°íƒ€(Others)\"] = Field(\n",
        "         description=\"ì§ˆë¬¸ì— ì‚¬ìš©ëœ ë©”ì¸ ì–¸ì–´\"\n",
        "    )    \n",
        "    explanation: str = Field(\n",
        "        description=\"ì–¸ì–´ ê°ì§€ ê·¼ê±°ì— ëŒ€í•œ ì§§ì€ ì„¤ëª…\"\n",
        "    )\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "language_detection_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"\"\"ë‹¹ì‹ ì€ ì–¸ì–´ ê°ì§€ ì „ë¬¸ê°€ë‹¤. \n",
        "        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³  ë¶„ì„í•´ì•¼ í•œë‹¤.\n",
        "        \n",
        "        ë‹¤ìŒ ì–¸ì–´ë“¤ì„ ì£¼ë¡œ êµ¬ë¶„í•œë‹¤:\n",
        "        - English: ì˜ì–´\n",
        "        - Korean: í•œêµ­ì–´\n",
        "        - Spanish: ìŠ¤í˜ì¸ì–´\n",
        "        - Chinese: ì¤‘êµ­ì–´\n",
        "        - Japanese: ì¼ë³¸ì–´\n",
        "        - Others: ê¸°íƒ€ ì–¸ì–´\n",
        "        \n",
        "        í…ìŠ¤íŠ¸ì˜ ë¬¸ì ì²´ê³„, ë‹¨ì–´ íŒ¨í„´, ë¬¸ë²• êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì–¸ì–´ë¥¼ íŒë³„í•œë‹¤.\"\"\"\n",
        "    ),\n",
        "    (\"human\", \"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•˜ì„¸ìš”: {question}\")\n",
        "])\n",
        "\n",
        "# êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì‚¬ìš©í•œ ì²´ì¸ êµ¬ì„±\n",
        "structured_llm = llm.with_structured_output(LanguageDetection)\n",
        "language_chain = language_detection_prompt | structured_llm\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "examples = [\n",
        "    \"What is the atomic number of carbon?\",\n",
        "    \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "    \"Â¿CuÃ¡l es el nÃºmero atÃ³mico del carbono?\",\n",
        "    \"ç¢³çš„åŸå­åºæ•°æ˜¯å¤šå°‘ï¼Ÿ\",\n",
        "    \"ç‚­ç´ ã®åŸå­ç•ªå·ã¯ä½•ã§ã™ã‹ï¼Ÿ\",\n",
        "    \"Qual Ã© o nÃºmero atÃ´mico do carbono?\"\n",
        "]\n",
        "\n",
        "# ê° ì˜ˆì‹œ ì²˜ë¦¬\n",
        "for example in examples:\n",
        "    result = language_chain.invoke({\"question\": example})\n",
        "    \n",
        "    print(f\"\\nì…ë ¥: {example}\")\n",
        "    print(f\"ì–¸ì–´: {result.detected_language}\")\n",
        "    print(f\"ì„¤ëª…: {result.explanation}\")\n",
        "    print(f\"--------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c273a56e",
      "metadata": {},
      "source": [
        "`(3) RunnableParallelì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰ ì²´ì¸`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "bf0b47c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì²˜ë¦¬ ê²°ê³¼:\n",
            "ë‹µë³€: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¶„ì•¼ë¥¼ ì°¾ì•„ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# ë‹µë³€ í…œí”Œë¦¿ ì •ì˜\n",
        "answer_template = \"\"\"\n",
        "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ì§ˆë¬¸ì— {language}ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
        "ì§ˆë¬¸: {question}\n",
        "\"\"\"\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ ë° ì²´ì¸ êµ¬ì„±\n",
        "answer_prompt = PromptTemplate.from_template(answer_template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# ë³‘ë ¬ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„± #ì„¸ê°€ì§€ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•œë‹¤.\n",
        "answer_chain = RunnableParallel({\n",
        "    \"topic\": classification_chain | RunnableLambda(lambda x: x.category),#ì´ ëŒë‹¤ ì•ˆì˜ê°’ì„ ëŸ¬ë„ˆë¸”ë¡œ ë§¤ê¾¸ë©´ ë°”ë¡œ ì»´í¬ë„ŒíŠ¸ë¡œ ì‚¬ìš©ê°€ëŠ¥í•¨.,            # ì£¼ì œ ë¶„ë¥˜ ì²´ì¸\n",
        "    \"language\": language_chain | RunnableLambda(lambda x: x.detected_language),         # ì–¸ì–´ ê°ì§€ ì²´ì¸\n",
        "    \"question\": itemgetter(\"question\")\n",
        "    }) | answer_prompt | llm | output_parser \n",
        " #    ì—”ì„œí”„ë¡¬í”„íŠ¸ì•ˆì— 3ê°€ì§€ê°€ë‚˜ì˜¤ê³  llmê°€ê³  ì•„ì›ƒí’‹íŒŒì„œì§€ë‚˜ê°„ë‹¤. # ì›ë³¸ ì§ˆë¬¸ ì¶”ì¶œ ê°ì²´ë¡œë¶€í„°ì˜ ì•„ë˜ì›ë³¸ì§ˆë¬¸ë§Œ ê°€ì ¸ì˜¤ëŠ”ê±°ë‹¤.\n",
        "# ì²´ì¸ ì‹¤í–‰ ì˜ˆì‹œ \n",
        "result = answer_chain.invoke({\n",
        "    \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "})\n",
        "\n",
        "print(\"ì²˜ë¦¬ ê²°ê³¼:\")\n",
        "print(f\"ë‹µë³€: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ddb27f",
      "metadata": {},
      "source": [
        "#### 4) **RunnablePassthrough**\n",
        "\n",
        "- **RunnablePassthrough**ëŠ” ì…ë ¥ê°’ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì—¬ ì›ë³¸ ë°ì´í„°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤\n",
        "\n",
        "- **RunnableParallel**ê³¼ í•¨ê»˜ ì‚¬ìš©ë˜ì–´ ì…ë ¥ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ í‚¤ë¡œ ë§¤í•‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "\n",
        "- **íˆ¬ëª…í•œ ë°ì´í„° íë¦„**ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…ê³¼ êµ¬ì„±ì´ ìš©ì´í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "11de1469",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': {'query': 'íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.'}, 'modified': 6}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import re\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x[\"query\"]).group())#ì „ë‹¬ëœë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬ì‹œí‚¨ë‹¤.,\n",
        ")\n",
        "\n",
        "runnable.invoke({\"query\": 'íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "346a12dc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': 'íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.', 'modified': 6}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke('íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d46b8",
      "metadata": {},
      "source": [
        "---\n",
        "# [ì‹¤ìŠµ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5b260a",
      "metadata": {},
      "source": [
        "- **ë‹¤ìŒê³¼ ê°™ì€ ìš”êµ¬ì‚¬í•­ì„ LCELë¡œ êµ¬í˜„í•©ë‹ˆë‹¤**\n",
        "   1. ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë‚´ìš©ì„ ìš”ì•½í•˜ê¸°\n",
        "   2. ìš”ì•½ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì • ë¶„ì„í•˜ê¸° (ê¸ì •, ë¶€ì •, ì¤‘ë¦½)\n",
        "   3. ìš”ì•½ëœ ë¬¸ì¥ê³¼ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b457e140",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# ===== ì—°ìŠµë¬¸ì œ 1: Pydantic ëª¨ë¸ ì •ì˜ =====\n",
        "# TODO: ì•„ë˜ í´ë˜ìŠ¤ë“¤ì˜ ë¹ˆ ë¶€ë¶„ì„ ì±„ìš°ì„¸ìš”\n",
        "\n",
        "class Summary(BaseModel):\n",
        "    \"\"\"í…ìŠ¤íŠ¸ ìš”ì•½\"\"\"\n",
        "    one_line_summary: None = Field(  # TODO: str íƒ€ì… ì§€ì •\n",
        "        description=None  # TODO: \"í•œ ë¬¸ì¥ ìš”ì•½\" ì„¤ëª… ì¶”ê°€\n",
        "    )\n",
        "    main_points: list[None] = Field(  # TODO: list[str] íƒ€ì… ì§€ì •\n",
        "        description=\"ì£¼ìš” í¬ì¸íŠ¸ 1~3ê°œ\"\n",
        "    )\n",
        "\n",
        "class SentimentResult(BaseModel):\n",
        "    \"\"\"ê°ì • ë¶„ì„ ê²°ê³¼\"\"\"\n",
        "    sentiment: None = Field(  # TODO: Literal[\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\"] íƒ€ì… ì§€ì •\n",
        "        description=\"ì „ë°˜ì ì¸ ê°ì •\"\n",
        "    )\n",
        "    intensity: None = Field(  # TODO: float íƒ€ì… ì§€ì •\n",
        "        description=None  # TODO: \"ê°ì •ì˜ ê°•ë„\" ì„¤ëª… ì¶”ê°€\n",
        "    )\n",
        "    key_phrases: None = Field(  # TODO: list[str] íƒ€ì… ì§€ì •\n",
        "        description=\"ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‘œí˜„(ìµœëŒ€ 5ê°œ)\"\n",
        "    )\n",
        "\n",
        "class TextAnalysis(BaseModel):\n",
        "    \"\"\"í…ìŠ¤íŠ¸ ì¢…í•© ë¶„ì„\"\"\"\n",
        "    summary: None = Field(  # TODO: Summary íƒ€ì… ì§€ì •\n",
        "        description=\"í…ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´\"\n",
        "    )\n",
        "    sentiment: None = Field(  # TODO: SentimentResult íƒ€ì… ì§€ì •\n",
        "        description=None  # TODO: \"ê°ì • ë¶„ì„ ê²°ê³¼\" ì„¤ëª… ì¶”ê°€\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c3949ede",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===== ì—°ìŠµë¬¸ì œ 2: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì™„ì„± =====\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m analysis_prompt = \u001b[43mChatPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: \"system\" ì—­í•  ì§€ì •\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;250;43m        \u001b[39;49m\u001b[33;43;03m\"\"\"ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ë‹¤.\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[33;43;03m        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³  ê°ì •ì„ ë¶„ì„í•œë‹¤.\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;43;03m        ìš”ì•½ ì‹œ:\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[33;43;03m        - í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[33;43;03m        - ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì •í™•íˆ 3ê°œ ì¶”ì¶œ\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[33;43;03m        ê°ì • ë¶„ì„ ì‹œ:\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[33;43;03m        - ì „ë°˜ì ì¸ ê°ì •ì„ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[33;43;03m        - ê°ì •ì˜ ê°•ë„ë¥¼ 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ í‰ê°€\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[33;43;03m        - ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‘œí˜„ ì¶”ì¶œ\"\"\"\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: \"human\" ì—­í• ê³¼ \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:\\n\\n{text}\" ë©”ì‹œì§€\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1149\u001b[39m, in \u001b[36mChatPromptTemplate.from_messages\u001b[39m\u001b[34m(cls, messages, template_format)\u001b[39m\n\u001b[32m   1100\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_messages\u001b[39m(\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   1103\u001b[39m     messages: Sequence[MessageLikeRepresentation],\n\u001b[32m   1104\u001b[39m     template_format: PromptTemplateFormat = \u001b[33m\"\u001b[39m\u001b[33mf-string\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1105\u001b[39m ) -> ChatPromptTemplate:\n\u001b[32m   1106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[32m   1107\u001b[39m \n\u001b[32m   1108\u001b[39m \u001b[33;03m    Examples:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1147\u001b[39m \n\u001b[32m   1148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:954\u001b[39m, in \u001b[36mChatPromptTemplate.__init__\u001b[39m\u001b[34m(self, messages, template_format, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    885\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    886\u001b[39m     messages: Sequence[MessageLikeRepresentation],\n\u001b[32m   (...)\u001b[39m\u001b[32m    889\u001b[39m     **kwargs: Any,\n\u001b[32m    890\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[32m    892\u001b[39m \n\u001b[32m    893\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    951\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    953\u001b[39m     messages_ = [\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m         \u001b[43m_convert_to_message_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    955\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m    956\u001b[39m     ]\n\u001b[32m    958\u001b[39m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[32m    959\u001b[39m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1442\u001b[39m, in \u001b[36m_convert_to_message_template\u001b[39m\u001b[34m(message, template_format)\u001b[39m\n\u001b[32m   1438\u001b[39m         message_ = _create_template_from_message_type(\n\u001b[32m   1439\u001b[39m             message_type_str, template, template_format=template_format\n\u001b[32m   1440\u001b[39m         )\n\u001b[32m   1441\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m         message_ = \u001b[43mmessage_type_str\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate_format\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1448\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "# ===== ì—°ìŠµë¬¸ì œ 2: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì™„ì„± =====\n",
        "analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        None,  # TODO: \"system\" ì—­í•  ì§€ì •\n",
        "        \"\"\"ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ë‹¤.\n",
        "        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³  ê°ì •ì„ ë¶„ì„í•œë‹¤.\n",
        "        \n",
        "        ìš”ì•½ ì‹œ:\n",
        "        - í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬\n",
        "        - ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì •í™•íˆ 3ê°œ ì¶”ì¶œ\n",
        "        \n",
        "        ê°ì • ë¶„ì„ ì‹œ:\n",
        "        - ì „ë°˜ì ì¸ ê°ì •ì„ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜\n",
        "        - ê°ì •ì˜ ê°•ë„ë¥¼ 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ í‰ê°€\n",
        "        - ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‘œí˜„ ì¶”ì¶œ\"\"\"\n",
        "    ),\n",
        "    (None, None)  # TODO: \"human\" ì—­í• ê³¼ \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:\\n\\n{text}\" ë©”ì‹œì§€\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8d725fc4",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (4059650643.py, line 3)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstructured_llm = llm.None(None)  # TODO: with_structured_output(TextAnalysis)\u001b[39m\n                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# ===== ì—°ìŠµë¬¸ì œ 3: ì²´ì¸ êµ¬ì„± =====\n",
        "# TODO: with_structured_output ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ LLM ìƒì„±\n",
        "structured_llm = llm.None(None)  # TODO: with_structured_output(TextAnalysis)\n",
        "\n",
        "# TODO: í”„ë¡¬í”„íŠ¸ì™€ êµ¬ì¡°í™”ëœ LLMì„ íŒŒì´í”„(|)ë¡œ ì—°ê²°\n",
        "analysis_chain = None  # TODO: analysis_prompt | structured_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c68a22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== ì—°ìŠµë¬¸ì œ 4: ì‹¤í–‰ ë° ê²°ê³¼ ì²˜ë¦¬ =====\n",
        "text = \"\"\"ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì–´ë‚˜ì„œ ì‹œí—˜ ì¤€ë¹„ë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ìœ¼ë¡œ ë³µìŠµì„ í–ˆë‹¤.\n",
        "ì‹œí—˜ì¥ì— ë“¤ì–´ê°€ì„œ ë¬¸ì œë¥¼ í’€ ë•ŒëŠ” ê¸´ì¥í–ˆì§€ë§Œ, í‰ì†Œì— ì—´ì‹¬íˆ ê³µë¶€í–ˆë˜ ë‚´ìš©ë“¤ì´ ì˜ ê¸°ì–µë‚¬ë‹¤.\n",
        "ì‹œí—˜ ì‹œê°„ì´ ëë‚˜ê³  ë‹µì•ˆì§€ë¥¼ ì œì¶œí•  ë•ŒëŠ” ìì‹ ê°ì´ ìˆì—ˆë‹¤.\n",
        "ê²°ê³¼ë¥¼ í™•ì¸í–ˆì„ ë•Œ ë§Œì ì„ ë°›ì•˜ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆê³ , ê·¸ ìˆœê°„ ì •ë§ ê¸°ë»¤ë‹¤.\n",
        "ì§€ë‚œ ëª‡ ì£¼ ë™ì•ˆ ë°¤ëŠ¦ê²Œê¹Œì§€ ê³µë¶€í–ˆë˜ ë…¸ë ¥ì´ ê²°ì‹¤ì„ ë§ºì€ ê²ƒ ê°™ì•„ ë¿Œë“¯í–ˆë‹¤.\n",
        "ì„ ìƒë‹˜ê»˜ì„œë„ ì¹­ì°¬í•´ ì£¼ì…”ì„œ ë”ìš± ê¸°ì˜ê³  ë³´ëŒì°¼ë‹¤.\n",
        "ì´ë²ˆ ê²½í—˜ì„ í†µí•´ ë…¸ë ¥í•˜ë©´ ë°˜ë“œì‹œ ì¢‹ì€ ê²°ê³¼ê°€ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ë‹¤ì‹œ í•œë²ˆ ê¹¨ë‹¬ì•˜ë‹¤.\"\"\"\n",
        "\n",
        "# TODO: chainì˜ invoke ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ì–»ê¸°\n",
        "result = analysis_chain.None({None: None})  # TODO: invoke({\"text\": text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e424f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== ì—°ìŠµë¬¸ì œ 5: ê²°ê³¼ ì¶œë ¥ =====\n",
        "print(\"=== ë¶„ì„ ê²°ê³¼ ===\")\n",
        "print(f\"\\nğŸ“ ìš”ì•½: {result.None.None}\")  # TODO: result.summary.one_line_summary\n",
        "\n",
        "print(f\"\\nğŸ“Œ ì£¼ìš” í¬ì¸íŠ¸:\")\n",
        "for i, point in enumerate(result.summary.None, 1):  # TODO: main_points ì ‘ê·¼\n",
        "    print(f\"  {i}. {point}\")\n",
        "\n",
        "print(f\"\\nğŸ˜Š ê°ì •: {result.None.None}\")  # TODO: result.sentiment.sentiment\n",
        "print(f\"ğŸ’ª ê°•ë„: {result.sentiment.None:.2f}\")  # TODO: intensity ì ‘ê·¼\n",
        "\n",
        "print(f\"\\nğŸ”‘ í•µì‹¬ í‘œí˜„:\")\n",
        "for phrase in result.None.None:  # TODO: sentiment.key_phrases ì ‘ê·¼\n",
        "    print(f\"  - {phrase}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8736bdc9",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>ğŸ’¡ ì •ë‹µ ë³´ê¸°</summary>\n",
        "\n",
        "```python\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Pydantic ëª¨ë¸ë“¤ ì •ì˜\n",
        "class Summary(BaseModel):\n",
        "    \"\"\"í…ìŠ¤íŠ¸ ìš”ì•½\"\"\"\n",
        "    one_line_summary: str = Field(\n",
        "        description=\"í•œ ë¬¸ì¥ ìš”ì•½\"\n",
        "    )\n",
        "    main_points: list[str] = Field(\n",
        "        description=\"ì£¼ìš” í¬ì¸íŠ¸ 1~3ê°œ\",\n",
        "    )\n",
        "\n",
        "class SentimentResult(BaseModel):\n",
        "    \"\"\"ê°ì • ë¶„ì„ ê²°ê³¼\"\"\"\n",
        "    sentiment: Literal[\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\"] = Field(\n",
        "        description=\"ì „ë°˜ì ì¸ ê°ì •\"\n",
        "    )\n",
        "    intensity: float = Field(\n",
        "        description=\"ê°ì •ì˜ ê°•ë„\"\n",
        "    )\n",
        "    key_phrases: list[str] = Field(\n",
        "        description=\"ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‘œí˜„(ìµœëŒ€ 5ê°œ)\"\n",
        "    )\n",
        "\n",
        "class TextAnalysis(BaseModel):\n",
        "    \"\"\"í…ìŠ¤íŠ¸ ì¢…í•© ë¶„ì„\"\"\"\n",
        "    summary: Summary = Field(\n",
        "        description=\"í…ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´\"\n",
        "    )\n",
        "    sentiment: SentimentResult = Field(\n",
        "        description=\"ê°ì • ë¶„ì„ ê²°ê³¼\"\n",
        "    )\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"\"\"ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ë‹¤.\n",
        "        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³  ê°ì •ì„ ë¶„ì„í•œë‹¤.\n",
        "        \n",
        "        ìš”ì•½ ì‹œ:\n",
        "        - í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬\n",
        "        - ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì •í™•íˆ 3ê°œ ì¶”ì¶œ\n",
        "        \n",
        "        ê°ì • ë¶„ì„ ì‹œ:\n",
        "        - ì „ë°˜ì ì¸ ê°ì •ì„ ê¸ì •/ë¶€ì •/ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜\n",
        "        - ê°ì •ì˜ ê°•ë„ë¥¼ 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ í‰ê°€\n",
        "        - ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‘œí˜„ ì¶”ì¶œ\"\"\"\n",
        "    ),\n",
        "    (\"human\", \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:\\n\\n{text}\")\n",
        "])\n",
        "\n",
        "# ì²´ì¸ êµ¬ì„±\n",
        "structured_llm = llm.with_structured_output(TextAnalysis)\n",
        "analysis_chain = analysis_prompt | structured_llm\n",
        "\n",
        "# ì‹¤í–‰\n",
        "text = \"\"\"ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì–´ë‚˜ì„œ ì‹œí—˜ ì¤€ë¹„ë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ìœ¼ë¡œ ë³µìŠµì„ í–ˆë‹¤.\n",
        "ì‹œí—˜ì¥ì— ë“¤ì–´ê°€ì„œ ë¬¸ì œë¥¼ í’€ ë•ŒëŠ” ê¸´ì¥í–ˆì§€ë§Œ, í‰ì†Œì— ì—´ì‹¬íˆ ê³µë¶€í–ˆë˜ ë‚´ìš©ë“¤ì´ ì˜ ê¸°ì–µë‚¬ë‹¤.\n",
        "ì‹œí—˜ ì‹œê°„ì´ ëë‚˜ê³  ë‹µì•ˆì§€ë¥¼ ì œì¶œí•  ë•ŒëŠ” ìì‹ ê°ì´ ìˆì—ˆë‹¤.\n",
        "ê²°ê³¼ë¥¼ í™•ì¸í–ˆì„ ë•Œ ë§Œì ì„ ë°›ì•˜ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆê³ , ê·¸ ìˆœê°„ ì •ë§ ê¸°ë»¤ë‹¤.\n",
        "ì§€ë‚œ ëª‡ ì£¼ ë™ì•ˆ ë°¤ëŠ¦ê²Œê¹Œì§€ ê³µë¶€í–ˆë˜ ë…¸ë ¥ì´ ê²°ì‹¤ì„ ë§ºì€ ê²ƒ ê°™ì•„ ë¿Œë“¯í–ˆë‹¤.\n",
        "ì„ ìƒë‹˜ê»˜ì„œë„ ì¹­ì°¬í•´ ì£¼ì…”ì„œ ë”ìš± ê¸°ì˜ê³  ë³´ëŒì°¼ë‹¤.\n",
        "ì´ë²ˆ ê²½í—˜ì„ í†µí•´ ë…¸ë ¥í•˜ë©´ ë°˜ë“œì‹œ ì¢‹ì€ ê²°ê³¼ê°€ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ë‹¤ì‹œ í•œë²ˆ ê¹¨ë‹¬ì•˜ë‹¤.\"\"\"\n",
        "\n",
        "result = analysis_chain.invoke({\"text\": text})\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"=== ë¶„ì„ ê²°ê³¼ ===\")\n",
        "print(f\"\\nğŸ“ ìš”ì•½: {result.summary.one_line_summary}\")\n",
        "\n",
        "print(f\"\\nğŸ“Œ ì£¼ìš” í¬ì¸íŠ¸:\")\n",
        "for i, point in enumerate(result.summary.main_points, 1):\n",
        "    print(f\"  {i}. {point}\")\n",
        "\n",
        "print(f\"\\nğŸ˜Š ê°ì •: {result.sentiment.sentiment}\")\n",
        "print(f\"ğŸ’ª ê°•ë„: {result.sentiment.intensity:.2f}\")\n",
        "\n",
        "print(f\"\\nğŸ”‘ í•µì‹¬ í‘œí˜„:\")\n",
        "for phrase in result.sentiment.key_phrases:\n",
        "    print(f\"  - {phrase}\")\n",
        "```\n",
        "</details>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "004-llm-agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
