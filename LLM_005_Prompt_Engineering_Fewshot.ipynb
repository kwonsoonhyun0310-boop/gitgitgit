{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Few-shot 프롬프팅\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/p7/4fhnsn7539q101qzrnk7dpkr0000gn/T/ipykernel_64873/537322193.py\", line 5, in <module>\n",
      "    from langchain_openai import ChatOpenAI\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_openai/__init__.py\", line 3, in <module>\n",
      "    from langchain_openai.chat_models import AzureChatOpenAI, ChatOpenAI\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/__init__.py\", line 3, in <module>\n",
      "    from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/azure.py\", line 11, in <module>\n",
      "    from langchain_core.language_models import LanguageModelInput\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/language_models/__init__.py\", line 110, in __getattr__\n",
      "    result = import_attr(attr_name, module_name, __spec__.parent)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/_import_utils.py\", line 35, in import_attr\n",
      "    module = import_module(f\".{module_name}\", package=package)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/language_models/base.py\", line 41, in <module>\n",
      "    from transformers import GPT2TokenizerFast  # type: ignore[import-not-found]\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/transformers/__init__.py\", line 27, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n",
      "    from .auto_docstring import (\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n",
      "    from .generic import ModelOutput\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/transformers/utils/generic.py\", line 51, in <module>\n",
      "    import torch\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/kwonsoonhyun/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Langfuse 설정\n",
    "langfuse = get_client()\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Zero-shot** 프롬프팅\n",
    "\n",
    "- **Zero-shot 프롬프팅**은 예시 없이 AI가 즉시 작업을 수행하는 기법입니다\n",
    "\n",
    "- 명확한 **지시사항**만으로 원하는 결과를 얻을 수 있어 **사용이 간단**합니다\n",
    "\n",
    "- 단순하고 직관적인 작업에 적합한 프롬프팅 방식이지만, 작업의 **복잡도에 따라 선택적 사용**이 필요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) without context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x141c1d160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero-shot 프롬프트 생성 #예시없이 사용한다.\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-zero-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"다음 시장에서 삼성전자의 경쟁업체를 설명해주세요: {{topic}}\", #토픿변수 랭퓨즈는 이중괄호\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"zero-shot\"] #태그 필터링\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 반도체 시장에서 삼성전자의 주요 경쟁업체는 다음과 같습니다:\n",
      "\n",
      "1. **엔비디아 (NVIDIA)**  \n",
      "   - 인공지능 및 딥러닝 분야에서 가장 선도적인 GPU 제조업체입니다. 특히 데이터센터용 AI 가속기와 자율주행, 로보틱스 등 다양한 AI 응용 분야에 강점을 가지고 있습니다.\n",
      "\n",
      "2. **인텔 (Intel)**  \n",
      "   - CPU뿐만 아니라 AI 가속기, FPGA, 그리고 AI 전용 칩 개발에 적극 투자하고 있습니다. 최근에는 AI 반도체 스타트업 인수와 자체 AI 칩 개발을 통해 시장 경쟁력을 강화하고 있습니다.\n",
      "\n",
      "3. **구글 (Google)**  \n",
      "   - TPU(Tensor Processing Unit)라는 AI 전용 반도체를 자체 개발하여 클라우드 AI 서비스에 활용하고 있습니다. 구글 클라우드 플랫폼을 통한 AI 반도체 서비스도 제공 중입니다.\n",
      "\n",
      "4. **AMD**  \n",
      "   - 고성능 GPU를 기반으로 AI 및 머신러닝 가속기 시장에 진출하고 있으며, 엔비디아와 경쟁 구도를 형성하고 있습니다.\n",
      "\n",
      "5. **화웨이 (Huawei)**  \n",
      "   - 자체 AI 칩셋인 Ascend 시리즈를 개발하여 데이터센터 및 엣지 컴퓨팅용 AI 반도체 시장을 공략하고 있습니다.\n",
      "\n",
      "6. **미디어텍 (MediaTek)**  \n",
      "   - 모바일 및 엣지 AI 반도체 시장에서 경쟁력을 갖추고 있으며, AI 기능이 강화된 칩셋을 출시하고 있습니다.\n",
      "\n",
      "이 외에도 여러 스타트업과 반도체 기업들이 AI 반도체 시장에 진출하고 있어 경쟁이 점차 치열해지고 있습니다. 삼성전자는 메모리 반도체뿐만 아니라 AI 연산에 최적화된 비메모리 반도체 개발에도 집중하며 이 시장에서 경쟁력을 강화하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Zero-shot 프롬프트 템플릿 사용\n",
    "zero_shot_template = langfuse.get_prompt(\"competitor-analysis-zero-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "zero_shot_prompt = PromptTemplate.from_template(\n",
    "    zero_shot_template.get_langchain_prompt()\n",
    ")\n",
    "zero_shot_prompt.metadata={\"langfuse_prompt\": zero_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "zero_shot_result = chain.invoke(\n",
    "    {\"topic\": \"인공지능 반도체\"}, #토픽으로 인공지능 전달\n",
    "    config={\"callbacks\": [langfuse_handler]} #초기화했던거 전달해주면 체인의 실행내용을 트래이싱 추적할 수 있다. 체인이 실행되고 인공지능 반도체 내용 아는거 llm이말함\n",
    ")\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) with context`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x141c87740>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero-shot with context 프롬프트 생성 \n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-zero-shot-context\",\n",
    "    type=\"text\", ##컨텍스트를 제공하는것 뿐이지 원샷은아니고 제로샷이다.\n",
    "    prompt=\"\"\"{{topic}} 시장에서 삼성전자의 경쟁업체를 설명해주세요. \n",
    "반드시 다음 제시된 뉴스에 근거해서 답변하세요:\n",
    "\n",
    "[뉴스]\n",
    "{{context}} \n",
    "\n",
    "[답변]\n",
    "\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"zero-shot\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]  \n",
      "인공지능 반도체 시장에서 삼성전자의 주요 경쟁업체는 현재 지배적인 위치를 차지하고 있는 엔비디아입니다. 삼성전자는 내년 초 자체 개발한 AI 가속기를 출시하여 엔비디아의 독점적 지위에 도전하고, 세계 최고의 반도체 제조업체로서의 위상을 강화하려는 전략을 추진하고 있습니다. 따라서 엔비디아가 삼성전자의 가장 큰 경쟁자로 볼 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot with context 프롬프트 템플릿 사용\n",
    "zero_shot_template = langfuse.get_prompt(\"competitor-analysis-zero-shot-context\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "zero_shot_prompt = PromptTemplate.from_template(\n",
    "    zero_shot_template.get_langchain_prompt()\n",
    ")\n",
    "zero_shot_prompt.metadata={\"langfuse_prompt\": zero_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "context = \"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\n",
    "\"\"\"\n",
    "\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(\n",
    "    {\"context\": context, \"topic\": topic},\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    "    )\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **One-shot** 프롬프팅\n",
    "\n",
    "- **One-shot 프롬프팅**은 하나의 예시를 통해 AI가 작업 패턴을 학습하는 기법입니다\n",
    "\n",
    "- **Zero-shot** 방식보다 더 나은 성능을 제공하며, **형식화된 작업**에 특히 효과적입니다\n",
    "\n",
    "- 단일 예시로 **품질 향상**이 가능하나, 해당 예시에 **과의존**할 수 있는 한계가 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\n",
      "샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\n",
      "구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x141c98770>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One-shot 프롬프트 템플릿 생성\n",
    "# 1. Zero-shot 프롬프트 템플릿에 예시(example)를 포함하도록 수정\n",
    "# 2. input_variables에 example_topic과 example_response 추가\n",
    "# 3. config에 예시들을 저장\n",
    "\n",
    "# 예시\n",
    "example_topic = \"스마트폰\"\n",
    "example_response = \"애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\\n샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\\n구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\"\n",
    "print(example_response) #프롬프트 자체로 랭퓨즈에 등록을해준다. \n",
    "\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-one-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"\"\"다음은 특정 시장에서 삼성전자의 경쟁업체를 설명하는 예시이다:\n",
    "\n",
    "시장: {{example_topic}}\n",
    "경쟁업체: {{example_response}}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {{topic}}\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"one-shot\"],\n",
    "    config={\n",
    "        \"example_topic\": example_topic,\n",
    "        \"example_response\": example_response #프롬프트의 컨피그 값을 가져와서 예시로보여주고 그럼 모델 대답도 예시처럼 따라간다 \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_shot_result:\n",
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(NVIDIA): AI 연산에 최적화된 GPU를 중심으로 시장을 선도하며, 데이터센터 및 자율주행 등 다양한 AI 응용 분야에서 강력한 입지 확보  \n",
      "- AMD: 고성능 GPU 및 CPU를 결합한 솔루션으로 AI 및 머신러닝 워크로드에 대응하며, 엔비디아와 경쟁 구도 형성  \n",
      "- 구글(Google): 자체 개발한 TPU(Tensor Processing Unit)를 통해 클라우드 기반 AI 연산에 특화된 반도체 제공, AI 서비스 최적화에 집중  \n",
      "- 인텔(Intel): AI 가속기 및 FPGA 기반 솔루션을 통해 데이터센터 및 엣지 컴퓨팅용 AI 반도체 시장 공략  \n",
      "- 화웨이(Huawei): AI 칩셋인 Ascend 시리즈를 통해 중국 내수 및 글로벌 시장에서 AI 반도체 경쟁력 강화  \n",
      "\n",
      "이들 기업은 삼성전자와 함께 AI 반도체 시장에서 기술력과 생태계 확장을 두고 경쟁하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 템플릿 사용\n",
    "one_shot_template = langfuse.get_prompt(\"competitor-analysis-one-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "one_shot_prompt = PromptTemplate.from_template(\n",
    "    one_shot_template.get_langchain_prompt()\n",
    ")\n",
    "one_shot_prompt.metadata={\"langfuse_prompt\": one_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# one_shot_prompt 적용한 체인 생성\n",
    "chain = one_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"example_topic\": one_shot_template.config.get(\"example_topic\"),\n",
    "        \"example_response\": one_shot_template.config.get(\"example_response\"),\n",
    "        \"topic\": topic\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    ")\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Few-shot** 프롬프팅\n",
    "\n",
    "- **Few-shot 프롬프팅**은 AI 모델에게 2-5개의 예시를 제공하여 학습시키는 방법입니다\n",
    "\n",
    "- 이 방식은 **Zero-shot**이나 **One-shot** 프롬프팅보다 더 우수한 성능을 보여주며, 복잡한 작업에서 특히 효과적입니다\n",
    "\n",
    "- Few-shot 프롬프팅은 높은 성능을 제공하지만, 긴 프롬프트로 인한 **비용 증가**를 고려해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x141c85a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 데이터 준비 회사이름 나라이름 예시를 조금더 짧은 문장으로. 대신 여러개로 등록해서 사용하는 이유는 관리하기가 편하다. 프롬프트를 땡겨올수가 있으니까.\n",
    "examples = \"\"\"\n",
    "시장: 스마트폰\n",
    "경쟁업체: \n",
    "- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\n",
    "- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\n",
    "- 구글(미국): Pixel로 AI 기능 강조\n",
    "\n",
    "시장: TV\n",
    "경쟁업체:\n",
    "- LG전자(한국): OLED 기술 경쟁\n",
    "- Sony(일본): 프리미엄 시장 경쟁\n",
    "- TCL(중국): 중저가 시장 공략\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot 프롬프트를 Langfuse에 저장 (예시는 config에 저장) 결과가 표현자체가 더 간결해졌다. 컨텍스트까지 제공하면 더 자세하게 제공된다.\n",
    "langfuse.create_prompt(\n",
    "    name=\"competitor-analysis-few-shot\",\n",
    "    type=\"text\",\n",
    "    prompt=\"\"\"다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\n",
    "\n",
    "{{examples}}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {{topic}}\"\"\",\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"competitor\", \"analysis\", \"few-shot\"],\n",
    "    config={\n",
    "        \"examples\": examples\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few_shot_result:\n",
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(미국): GPU 기반 AI 연산 시장 선도, 데이터센터 및 자율주행용 AI 칩 강세  \n",
      "- AMD(미국): 고성능 GPU 및 CPU 통합 솔루션 제공, AI 및 머신러닝 가속화  \n",
      "- 화웨이(중국): 자체 개발한 AI 칩(Ascend 시리즈)으로 중국 내수 및 글로벌 시장 공략  \n",
      "- 텐센트(중국): AI 반도체 개발 투자 확대, 클라우드 AI 서비스와 연계  \n",
      "- 인텔(미국): AI 전용 프로세서 및 FPGA 개발, 데이터센터 AI 솔루션 강화\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 사용\n",
    "few_shot_template = langfuse.get_prompt(\"competitor-analysis-few-shot\")\n",
    "\n",
    "# Langfuse 프롬프트를 LangChain과 통합\n",
    "few_shot_prompt = PromptTemplate.from_template(\n",
    "    few_shot_template.get_langchain_prompt()\n",
    ")\n",
    "few_shot_prompt.metadata={\"langfuse_prompt\": few_shot_template}  # Langfuse 자동 링크를 위한 메타데이터\n",
    "\n",
    "# few_shot_prompt 적용한 체인 생성\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Few-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "few_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"examples\": few_shot_template.config.get(\"examples\"),\n",
    "        \"topic\": topic\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}  # Langfuse 트레이싱을 위한 콜백\n",
    ")\n",
    "\n",
    "print(f\"few_shot_result:\")\n",
    "print(few_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) FewShotChatMessagePromptTemplate 사용`\n",
    "\n",
    "* FewShotChatMessagePromptTemplate는 LangChain에서 제공하는 템플릿으로, **미리 정의된 고정된 예제들(Fixed Examples)** 을 프롬프트에 포함시켜 모델이 일관된 형식과 품질의 응답을 생성할 수 있도록 돕습니다.\n",
    "\n",
    "* 이 방식은 특히 특정 형식이나 구조를 가진 출력이 필요한 경우(예: JSON 형식, 특정 분석 리포트 형식 등) 매우 유용하며, 예제들이 고정되어 있어 결과의 일관성을 보장할 수 있습니다.\n",
    "\n",
    "* 단, 고정된 예제를 사용하기 때문에 상황에 따라 유연하게 대응하기 어려울 수 있으며, 모든 케이스를 커버하기 위해서는 신중한 예제 선택이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
      "지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
      "입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
      "\n",
      "AI: 의대 | 정원 | 확대\n",
      "Human: \n",
      "세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
      "전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
      "\n",
      "AI: 세계보건기구 | 건강위기 | 국제\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from textwrap import dedent # text의 모든 줄에서 같은 선행 공백을 제거하는 함수, 앞부분 공백만 사라짐\n",
    "\n",
    "# 예시 데이터 정의 : 뉴스 텍스트(input) + 키워드 추출 결과 (output)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"세계보건기구 | 건강위기 | 국제\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 각 예시를 포맷팅할 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,      # 예시 포맷팅 템플릿\n",
    "    examples=examples                   # 예시 데이터 리스트 -> 예시 포맷팅 템플릿에 적용\n",
    ")\n",
    "\n",
    "# Few-shot 프롬프트 출력 예시\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 뉴스 텍스트에서 핵심 키워드 3개를 추출하는 전문가입니다.\n",
      "Human: \n",
      "정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
      "지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
      "입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
      "\n",
      "AI: 의대 | 정원 | 확대\n",
      "Human: \n",
      "세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
      "전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
      "\n",
      "AI: 세계보건기구 | 건강위기 | 국제\n",
      "Human: 테스트 뉴스 기사입니다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 프롬프트 템플릿 생성 \n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 텍스트에서 핵심 키워드 3개를 추출하는 전문가입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "#앞에서 템플릿을 사용해놓으니까 다음것도 잘 진행된다.\n",
    "# 프롬프트 템플릿 출력\n",
    "print(final_prompt.format(input=\"테스트 뉴스 기사입니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 키워드 추출 체인 실행 실제로는 체인안에서 세개를 꺼내온다.\n",
    "result = chain.invoke({\n",
    "    \"input\": dedent(\"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "                    이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "                    세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\"\"\")\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langfuse에서 구현 (메시지플레이스홀더 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.ChatPromptClient at 0x141c62ab0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few-shot 프롬프트를 Langfuse에 생성 (Message Placeholder 사용)\n",
    "langfuse.create_prompt(\n",
    "    name=\"keyword-extractor-few-shot\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"당신은 뉴스 텍스트에서 핵심 키워드를 추출하는 전문가입니다.\n",
    "다음 지침을 따라주세요:\n",
    "- 가장 중요한 키워드 3개를 추출\n",
    "- 키워드는 ' | ' 로 구분\n",
    "- 명사 위주로 추출\n",
    "- 고유명사와 핵심 개념 우선\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"placeholder\",  #예시는 메세지플레이스홀더타입으로 사용\n",
    "            \"name\": \"few_shot_examples\"  # Few-shot 예시들이 들어갈 placeholder 이거안써도 잘 파악하겟지만 예시를 쓴다.\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"다음 뉴스 텍스트에서 핵심 키워드를 추출해주세요:\\n\\n{{input_text}}\"\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"keyword\", \"extraction\", \"few-shot\", \"news\"],\n",
    "    config={\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"temperature\": 0.1,  # 일관성을 위해 낮은 temperature\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Placeholders ['few_shot_examples'] have not been resolved. Pass them as keyword arguments to compile().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전기차 | 보조금 | 탄소중립\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Langfuse 프롬프트 가져오기\n",
    "prompt = langfuse.get_prompt(\"keyword-extractor-few-shot\", type=\"chat\")\n",
    "\n",
    "# LangChain과 통합하여 실행\n",
    "langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "    prompt.get_langchain_prompt()\n",
    ")\n",
    "\n",
    "# 메타데이터 설정 이거해야 모델이 걸린다\n",
    "langchain_prompt.metadata = {\"langfuse_prompt\": prompt}\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(\n",
    "    model=prompt.config.get(\"model\", \"gpt-4.1-mini\"),\n",
    "    temperature=prompt.config.get(\"temperature\", 0.1),\n",
    "    max_completion_tokens=prompt.config.get(\"max_tokens\", 100)\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = langchain_prompt | model\n",
    "\n",
    "# Few-shot 프롬프트 실행\n",
    "\n",
    "# 뉴스 텍스트 정의\n",
    "news_text = dedent(\"\"\"\n",
    "정부는 내년부터 전기차 구매 보조금을 기존 대비 30% 확대하기로 결정했다.\n",
    "탄소 중립 목표 달성과 친환경 자동차 산업 육성을 위한 조치로, \n",
    "개인 구매자는 최대 800만원, 법인은 최대 500만원까지 지원받을 수 있다.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Few-shot 예시 데이터 정의\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"세계보건기구 | 건강위기 | 국제협력\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "                        삼성전자가 새로운 갤럭시 스마트폰 시리즈를 내년 1분기에 출시할 예정이라고 발표했다.\n",
    "                        인공지능 기능이 대폭 강화되고 배터리 수명도 20% 향상될 것으로 예상된다.\n",
    "                        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"삼성전자 | 갤럭시 | 인공지능\"\n",
    "    }\n",
    "]\n",
    "#아래 체인으로 실제 뉴스를 전달하면 아래로  Inputext로 연결이 되고 예시는 플레이스홀더로 전달된다 6개의 주고받은것들이 플레이스홀더로. 메타데이터는 통과되고 세개 키워드\n",
    "#시스템메세지 다음에 플레이스홀더에 적히면서 모델이 이해를한다. 유저메세지는 유저가보내는것을 알아서 히스토리처럼 기억하고\n",
    "#유저가 입력을 했을때, \n",
    "response = chain.invoke(\n",
    "    input={\n",
    "        \"input_text\": news_text,\n",
    "        \"few_shot_examples\": few_shot_examples\n",
    "    },\n",
    "    config={\n",
    "        \"callbacks\": [langfuse_handler],\n",
    "        \"metadata\": {\n",
    "            \"user_id\": \"user_123\",\n",
    "            \"task\": \"keyword_extraction\",\n",
    "            \"method\": \"few_shot_learning\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) Dynamic Few-Shot Prompting`\n",
    "\n",
    "* **Dynamic Few-Shot Prompting**은 상황에 따라 적절한 예시를 동적으로 선택하여 사용하는 고급 프롬프팅 기법으로, **BaseExampleSelector**를 통해 입력값과 가장 연관성이 높은 예시들을 자동으로 선별합니다.\n",
    "\n",
    "* 대표적으로 **SemanticSimilarityExampleSelector**는 의미적 유사도를 기반으로 예시를 선택하며, 이를 통해 주어진 입력 상황에 가장 적합한 예시들만을 효율적으로 활용할 수 있습니다.\n",
    "\n",
    "* **example_prompt**를 통해 선택된 예시들을 AI 시스템이 이해하기 쉬운 형태(예: human-AI 대화 , human-function call)로 변환하여 더 효과적인 학습과 응답 생성이 가능하게 합니다.\n",
    "\n",
    "\n",
    "- **장점**\n",
    "\n",
    "    - 상황에 맞는 가장 연관성 높은 예시만을 선택적으로 활용할 수 있다\n",
    "    - 프롬프트의 길이를 효율적으로 관리할 수 있다\n",
    "    - 응답의 일관성과 품질을 향상시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m embeddings = OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mbge-m3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 벡터 스토어 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m vector_store = \u001b[43mInMemoryVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_vectorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 벡터화할 텍스트 리스트\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# 임베딩 모델\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 메타데이터: 예시 데이터\u001b[39;49;00m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# VectorStore에 저장된 Document 개수 확인\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVectorStore에 저장된 Document 개수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(vector_store.store.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/in_memory.py:497\u001b[39m, in \u001b[36mInMemoryVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    492\u001b[39m     **kwargs: Any,\n\u001b[32m    493\u001b[39m ) -> InMemoryVectorStore:\n\u001b[32m    494\u001b[39m     store = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    495\u001b[39m         embedding=embedding,\n\u001b[32m    496\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:94\u001b[39m, in \u001b[36mVectorStore.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     91\u001b[39m         \u001b[38;5;66;03m# For backward compatibility\u001b[39;00m\n\u001b[32m     92\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_texts` has not been implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/in_memory.py:194\u001b[39m, in \u001b[36mInMemoryVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, ids, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_documents\u001b[39m(\n\u001b[32m    188\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    191\u001b[39m     **kwargs: Any,\n\u001b[32m    192\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    193\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     vectors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) != \u001b[38;5;28mlen\u001b[39m(texts):\n\u001b[32m    197\u001b[39m         msg = (\n\u001b[32m    198\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mids must be the same length as texts. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ids and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m texts.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/langchain_ollama/embeddings.py:301\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    296\u001b[39m     msg = (\n\u001b[32m    297\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOllama client is not initialized. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    298\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure Ollama is running and the model is loaded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    299\u001b[39m     )\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ollama/_client.py:393\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive, dimensions)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    385\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    386\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m   dimensions: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    392\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ollama/_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sesac/004_llm_agent/.venv/lib/python3.12/site-packages/ollama/_client.py:135\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_core.vectorstores import InMemoryVectorStore # type: ignore\n",
    "\n",
    "# 고객 문의 유형별 응대 예시 데이터 랭체인에 구현돼있다. 임베딩모델을 사용한다. \n",
    "# few shot 예시도 상황에 따른 질문에 따라서 사용자 질문에관련된 faq만 가져와서 프롬프트에 넣어서  rag처럼 컨텍스트 가져오는 아이디어를 가져오는 개념이다.\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"환불 절차가 어떻게 되나요?\",\n",
    "        \"output\": \"환불 절차는 다음과 같습니다:\\n1. 구매내역에서 환불을 신청해주세요\\n2. 반품 상품을 발송해주세요\\n3. 상품 검수 후 3-5일 내 환불이 완료됩니다\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"배송이 늦어지고 있어요\", \n",
    "        \"output\": \"불편을 드려 죄송합니다. 주문번호를 알려주시면 배송 상태를 즉시 확인해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"옷 사이즈가 안 맞아요\",\n",
    "        \"output\": \"사이즈 교환은 무료로 진행됩니다. 교환 신청 후 동일 상품의 다른 사이즈로 발송해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"제품이 불량이에요\",\n",
    "        \"output\": \"불편을 드려 대단히 죄송합니다. 불량 부분 사진과 함께 1:1 문의에 접수해주시면 빠르게 처리해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"주문을 취소하고 싶어요\",\n",
    "        \"output\": \"주문 취소는 배송 전까지 가능합니다. 마이페이지에서 주문 취소를 진행해주시거나 고객센터로 연락주세요.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"할인 쿠폰이 적용이 안 돼요\",\n",
    "        \"output\": \"쿠폰 사용 조건을 확인해주세요. 최소 구매 금액이나 적용 상품에 제한이 있을 수 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"회원가입이 안 돼요\",\n",
    "        \"output\": \"회원가입 시 필수 정보를 모두 입력해주세요. 문제가 지속되면 고객센터로 연락주시기 바랍니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 데이터를 벡터화할 텍스트로 변환  질문 답변을 둘다 하나의 임베딩으로 나눴다.근데 따로 질문 , 답변 임베딩 따로하는게 낫지 않나? 이런 생각.\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "\n",
    "# Ollama 임베딩 모델 생성 텍스트를 올라마 사용해서 벡터임베딩저장할거다\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 벡터 스토어 생성 #벡터스토어는 크로마나 파이스사용하면되고\n",
    "vector_store = InMemoryVectorStore.from_texts(\n",
    "    to_vectorize,    # 벡터화할 텍스트 리스트\n",
    "    embeddings,      # 임베딩 모델\n",
    "    metadatas=examples    # 메타데이터: 예시 데이터 , 벡터스토어에 7개의 예시를 벡터화해놓는다.\n",
    "    )\n",
    "\n",
    "# VectorStore에 저장된 Document 개수 확인 랭체인의 다큐멘트로 저장되는데 원본 데이터가 메타데이터가된다.\n",
    "print(f\"VectorStore에 저장된 Document 개수: {len(vector_store.store.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 유사한 2개의 예시를 선택하는 selector 생성, 맥락적 의미를 가져오는 도구를 사용해서 2개를 벡터 비슷한거를 가져오는거다. \n",
    "#랭체인의 구현에서 그걸 가져온다. 예시를 벡터에서 가져온다. 벡터스토어에서 질문을 임베딩해서, 벡터스토어에서 검색해서 가져온다. 리턴할때 메타데이터를 리턴한다.\n",
    "#랭체인에 메모리에 잠깐 저장해놓는 거를 가져온다.\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vector_store,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 프롬프트 템플릿 생성, 이걸 퓨샷 예제 가져오는 거를 똑같이하는데, 차이는 이그젬플을 셀렉터로 유사한거를 가져오는걸로한다.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 생성 , 예제를 처리해주는 별도의 템플릿을 처리한다.\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절하고 전문적인 고객 서비스 담당자입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "pprint(final_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 체인 생성 #이걸 체인으로 구성한다. 그러면 최종 답변이 나온다. 여기서는 시스템프롬프트를 더 명확하게해야한다. 내용을 제대로할건지 구조만 할건지. 불량일때랑 파손일때랑 다를수도있으니까\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"input\": \"상품이 파손되어 왔어요\"\n",
    "})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- langfuse에서 구현 (메시지플레이스홀더 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse에 Semantic Few-shot 프롬프트 생성 랭퓨즈가 로그를 확인하는게 무료여서 랭스미스는 유료여서 \n",
    "langfuse.create_prompt(\n",
    "    name=\"customer-service-semantic-few-shot\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"당신은 친절하고 전문적인 고객 서비스 담당자입니다. 고객의 문의에 정확하고 도움이 되는 답변을 제공해주세요.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"placeholder\",\n",
    "            \"name\": \"selected_examples\"  # 유사도 기반으로 선택된 예시들\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \n",
    "            \"content\": \"{{customer_inquiry}}\"  # 실제 고객 문의\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"production\"],\n",
    "    tags=[\"customer-service\", \"semantic-similarity\", \"few-shot\"],\n",
    "    config={\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 예시들을 메시지 형태로 변환\n",
    "selected_examples_messages = []\n",
    "for example in selected_examples:\n",
    "    selected_examples_messages.extend([\n",
    "        {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "    ])\n",
    "\n",
    "for message in selected_examples_messages:\n",
    "    print(message)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 Few-shot 프롬프트 실행 함수\n",
    "def run_semantic_few_shot(customer_inquiry, k=2):\n",
    "    \"\"\"고객 문의에 대해 유사도 기반 Few-shot 프롬프트 실행\"\"\"\n",
    "    \n",
    "    # 유사한 예시들을 선택\n",
    "    selected_examples_raw = example_selector.select_examples({\"input\": customer_inquiry})\n",
    "    \n",
    "    # 선택된 예시들을 메시지 형태로 변환\n",
    "    selected_examples_messages = []\n",
    "    for example in selected_examples_raw:\n",
    "        selected_examples_messages.extend([\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ])\n",
    "    \n",
    "    # Langfuse 프롬프트 가져오기\n",
    "    prompt = langfuse.get_prompt(\"customer-service-semantic-few-shot\", type=\"chat\")\n",
    "\n",
    "    langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "        prompt.get_langchain_prompt()\n",
    "    )\n",
    "    langchain_prompt.metadata = {\"langfuse_prompt\": prompt}\n",
    "\n",
    "\n",
    "    compiled_prompt = prompt.compile(\n",
    "        customer_inquiry=customer_inquiry,\n",
    "        selected_examples=selected_examples_messages\n",
    "    )\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = ChatOpenAI(\n",
    "        model=prompt.config.get(\"model\", \"gpt-4.1-mini\"),\n",
    "        temperature=prompt.config.get(\"temperature\", 0.7),\n",
    "        max_completion_tokens=prompt.config.get(\"max_tokens\", 300)\n",
    "    )\n",
    "\n",
    "    # LangChain 체인 설정\n",
    "    chain = langchain_prompt | model\n",
    "\n",
    "    # 체인 실행\n",
    "    response = chain.invoke(\n",
    "        input={\n",
    "            \"customer_inquiry\": customer_inquiry,\n",
    "            \"selected_examples\": selected_examples_messages\n",
    "        },\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "    \n",
    "    return response, selected_examples_messages\n",
    "\n",
    "# 테스트 실행\n",
    "test_inquiry = \"상품이 파손되어 왔어요\"\n",
    "response, selected_examples = run_semantic_few_shot(test_inquiry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)\n",
    "print(\"=\" * 80)\n",
    "for message in selected_examples:\n",
    "    print(message)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "004-llm-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
